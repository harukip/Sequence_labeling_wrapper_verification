{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import prepare_train_with_set as prepare\n",
    "import os\n",
    "import func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    set_total = 0\n",
    "    # How many Set\n",
    "    ALL = True\n",
    "    if not ALL:\n",
    "        set_num = 1\n",
    "    DEBUG = False\n",
    "    \n",
    "    current_path = os.path.join(os.path.expanduser(\"~\"), \"jupyter\", \"web_verification\")\n",
    "    data, Set_idx = prepare.train_file_generate(set_total, current_path)\n",
    "    \n",
    "    max_num_train = func.load_data_num(data)\n",
    "    \n",
    "    x_train, y_train, _ = func.CRFSuite_proccess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check max_num in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the train file and test file to check max number of nodes for each page to give the number for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_train, max_label_train = load_data_num(\"./data/train_raw.csv\", True)\n",
    "max_num_test = load_data_num(\"./data/ytest_raw.csv\", False)\n",
    "max_num = max(max_num_train, max_num_test)\n",
    "if DEBUG:\n",
    "    print(max_num_train)\n",
    "    print(max_num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Set index File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Set_idx file to check which label is a Set in the training file generated by the training file generation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set_dict={}\n",
    "if set_total > 0:\n",
    "    Set_dict = {}\n",
    "    with open(\"./data/Set_idx.txt\", \"r\") as set_file:\n",
    "        Set_dict = eval(set_file.readline())\n",
    "    col_set_dict = dict(map(reversed, Set_dict.items()))\n",
    "    if DEBUG:\n",
    "        print(Set_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Training file and convert into CRF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = max_label_train\n",
    "df = get_df(\"./data/train_raw.csv\")\n",
    "feature_train, label_train, out_train = load_data_csv(df)\n",
    "page_num = int(len(feature_train)/max_num)\n",
    "#input_shape = feature_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    c1=0.1,\n",
    "    max_iterations=50\n",
    ")\n",
    "feature_train = feature_train.tolist()\n",
    "label_train = label_train.tolist()\n",
    "X_train = [sent2features(feature_train)]\n",
    "y_train = [sent2labels(label_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training and recording the time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "crf.fit(X_train, y_train)\n",
    "t = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = get_df(\"./data/ytest_raw.csv\")\n",
    "feature_test, label_test, out_test = load_data_csv(df)\n",
    "\n",
    "feature_test = feature_test.tolist()\n",
    "label_test = label_test.tolist()\n",
    "X_test = [sent2features(feature_test)]\n",
    "page_test = int(len(feature_test)/max_num)\n",
    "if DEBUG:\n",
    "    print(page_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test file and record the testing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "ts_start = time.time()\n",
    "y_pred = crf.predict(X_test)\n",
    "ts = time.time()-ts_start\n",
    "y_pred = np.array(y_pred)\n",
    "result = np.reshape(y_pred, [page_test, max_num])\n",
    "result = result.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Column Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Column type from TableA for file ColType output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_type = []\n",
    "with open(\"./data/TableA.txt\", \"r\") as file:\n",
    "    line = file.readline()\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    while(slot[0]!=\"ColType\"):\n",
    "        line = file.readline()\n",
    "        slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    col_type = slot[1:]\n",
    "if DEBUG:\n",
    "    print(col_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File prediction output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the prediction.csv file for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set_data = []\n",
    "with open(\"./crfsuite/data/predictions.csv\", \"w\") as file: # Create prediction file\n",
    "    for col in col_type: # loop to write the Col type\n",
    "        file.write(col + \"\\t\")\n",
    "        if DEBUG:\n",
    "            print(col + \"\\t\", end='')\n",
    "    file.write(\"\\n\")\n",
    "    for page in tqdm(range(len(result))): # Loop each page\n",
    "        sets = []\n",
    "        for label in range(max_label + 1): # Loop whole label\n",
    "            if DEBUG:\n",
    "                print(\"Label: \" + str(label))\n",
    "            if label == 0:\n",
    "                continue\n",
    "            empty = True\n",
    "            isset = False\n",
    "            data = []\n",
    "            for node in range(len(result[page])):\n",
    "                if result[page][node] == label:\n",
    "                    if empty == False and not isset:\n",
    "                        if DEBUG:\n",
    "                            print(\" \", end='')\n",
    "                        file.write(\" \")\n",
    "                    empty = False\n",
    "                    if label in col_set_dict.keys() and set_total > 0: # That col is a Set\n",
    "                        isset = True\n",
    "                        data.append(node)\n",
    "                        if DEBUG:\n",
    "                            print(\"Append:\" + str(node))\n",
    "                    else:\n",
    "                        if DEBUG:\n",
    "                            print(str(node), end='')\n",
    "                        file.write(str(node))\n",
    "            if label in col_set_dict.keys() and set_total > 0: # That col is a Set\n",
    "                if DEBUG:\n",
    "                    print(str(col_set_dict[label])+\"-\"+str(page), end='')\n",
    "                file.write(str(col_set_dict[label])+\"-\"+str(page))\n",
    "                sets.append(data)\n",
    "            if DEBUG:\n",
    "                print(\"\\t\", end='')\n",
    "            file.write(\"\\t\")\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "        file.write(\"\\n\")\n",
    "        if DEBUG:\n",
    "            print(data)\n",
    "        Set_data.append(sets)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set data output for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the Set data that being predicted in the Set by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crfsuite/set/Set_data.txt\", \"w\") as set_train_file:\n",
    "        tmp = str(Set_data)\n",
    "        set_train_file.write(tmp)\n",
    "        if DEBUG:\n",
    "            print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set Train File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate train file for Set Model from DCADE Set Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_count = []\n",
    "if set_total > 0:\n",
    "    for set_t in range(set_total):\n",
    "        with open(\"./data/Set-\"+ str(set_t+1) +\".txt\", \"r\") as set_file:\n",
    "            set_tmp = []\n",
    "            output_name = \"./crfsuite/set/Set-\"+ str(set_t+1) +\"_train_raw.csv\"\n",
    "            if DEBUG:\n",
    "                print(\"Generating:\" + output_name + \"\\n\")\n",
    "            output = open(output_name, \"w\")\n",
    "            output.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tLabel\\n\")\n",
    "            line = set_file.readline()\n",
    "            slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            while(slot[0]!=\"ColType\"): \n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            with open(\"./set/Set-\"+ str(set_t+1) +\"_coltype.txt\", \"w\") as col_file:\n",
    "                col_file.write(str(slot[1:]))\n",
    "            line = set_file.readline() # First line of data\n",
    "            page_num = 0\n",
    "            count = 0\n",
    "            while(line != \"\"):\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                data_info = slot[0].split(\"-\")\n",
    "                if(page_num != int(data_info[1])):\n",
    "                    set_tmp.append(count)\n",
    "                    count = 0\n",
    "                set_num = int(data_info[0])\n",
    "                page_num = int(data_info[1])\n",
    "                if DEBUG:\n",
    "                    print(str(data_info[0])+\"-\"+str(data_info[1])+\"-\"+str(data_info[2]))\n",
    "                idx = 1\n",
    "                sub_list = slot[1:]\n",
    "                while(\"\" in sub_list):\n",
    "                    sub_list.remove(\"\")\n",
    "                while(\" \" in sub_list):\n",
    "                    sub_list.remove(\" \")\n",
    "                for element in sub_list:\n",
    "                    count += 1\n",
    "                    if DEBUG:\n",
    "                        print(element)\n",
    "                    element = int(element)\n",
    "                    #print(content_train[page_num][element])\n",
    "                    output.write(str(feature_train[page_num*max_num+element][0])+\"\\t\")\n",
    "                    output.write(str(feature_train[page_num*max_num+element][1])+\"\\t\")\n",
    "                    output.write(str(feature_train[page_num*max_num+element][2])+\"\\t\")\n",
    "                    output.write(str(feature_train[page_num*max_num+element][3])+\"\\t\")\n",
    "                    output.write(str(feature_train[page_num*max_num+element][4])+\"\\t\")\n",
    "                    output.write(str(feature_train[page_num*max_num+element][5])+\"\\t\")\n",
    "                    output.write(str(idx) + \"\\n\")\n",
    "                    if DEBUG:\n",
    "                        print(feature_train[page_num*max_num+element][0])\n",
    "                    idx += 1\n",
    "                line = set_file.readline()\n",
    "            set_tmp.append(count)\n",
    "            output.close()\n",
    "        set_data_count.append(set_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crfsuite/set/set_train_count.txt\", \"w\") as file:\n",
    "        file.write(str(set_data_count))\n",
    "        if DEBUG:\n",
    "            print(set_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set Test file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test file from node data being predicted in a Set by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_count = []\n",
    "if set_total > 0:\n",
    "    for set_t in range(set_total):\n",
    "        set_tmp = []\n",
    "        with open(\"./crfsuite/set/Set-\"+ str(set_t+1) +\"_ytest_raw.csv\", \"w\") as set_file:\n",
    "            set_file.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tLabel\\n\")\n",
    "            for pages in tqdm(range(len(Set_data))):\n",
    "                count = 0\n",
    "                for node in Set_data[pages][set_t]:\n",
    "                    count += 1\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][0])+\"\\t\")\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][1])+\"\\t\")\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][2])+\"\\t\")\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][3])+\"\\t\")\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][4])+\"\\t\")\n",
    "                    set_file.write(str(feature_test[pages*max_num+node][5])+\"\\t\")\n",
    "                    set_file.write(str(0) + \"\\n\")\n",
    "                set_tmp.append(count)\n",
    "        set_data_count.append(set_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crfsuite/set/set_test_count.txt\", \"w\") as file:\n",
    "        file.write(str(set_data_count))\n",
    "        if DEBUG:\n",
    "            print(set_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_c = len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_num_set(set_data_count, set_total):\n",
    "    max_set = []\n",
    "    for i in range(set_total):\n",
    "        max_set.append(0)\n",
    "    for sets in range(len(set_data_count)):\n",
    "        max_set[sets] = max(set_data_count[sets])\n",
    "    return max_set\n",
    "\n",
    "def feature_padding_set(df, set_count, set_num):\n",
    "    feature = []\n",
    "    count = 0\n",
    "    for pages in set_count[set_num-1]:\n",
    "        set_len = pages\n",
    "        for i in range(set_len):\n",
    "            feature.append(df[count])\n",
    "            count += 1\n",
    "        if set_len != max_set[set_num-1]:\n",
    "            for i in range(max_set[set_num-1]-set_len):\n",
    "                feature.append(9999)\n",
    "    return feature\n",
    "\n",
    "def one_of_n(ans, total):\n",
    "    tmp = []\n",
    "    for i in range(int(total)):\n",
    "        if ans == i:\n",
    "            tmp.append(1.0)\n",
    "        else:\n",
    "            tmp.append(0.0)\n",
    "    return tmp\n",
    "\n",
    "def label_padding_set(df, set_count, set_num):\n",
    "    label = []\n",
    "    count = 0\n",
    "    for pages in set_count[set_num-1]:\n",
    "        set_len = pages\n",
    "        for i in range(set_len):\n",
    "            label.append(df[count])\n",
    "            count += 1\n",
    "        if set_len != max_set[set_num-1]:\n",
    "            for i in range(max_set[set_num-1]-set_len):\n",
    "                label.append(0)\n",
    "    return label\n",
    "\n",
    "def to_train_array_set(df, set_count, set_num):\n",
    "    feature_1 = np.array(feature_padding_set(df['Leafnode'], set_count, set_num))\n",
    "    feature_2 = np.array(feature_padding_set(df['PTypeSet'], set_count, set_num))\n",
    "    feature_3 = np.array(feature_padding_set(df['TypeSet'], set_count, set_num))\n",
    "    feature_4 = np.array(feature_padding_set(df['Contentid'], set_count, set_num))\n",
    "    feature_5 = np.array(feature_padding_set(df['Pathid'], set_count, set_num))\n",
    "    feature_6 = np.array(feature_padding_set(df['Simseqid'], set_count, set_num))\n",
    "    \n",
    "    feature_1 = np.expand_dims(feature_1, -1)\n",
    "    feature_2 = np.expand_dims(feature_2, -1)\n",
    "    feature_3 = np.expand_dims(feature_3, -1)\n",
    "    feature_4 = np.expand_dims(feature_4, -1)\n",
    "    feature_5 = np.expand_dims(feature_5, -1)\n",
    "    feature_6 = np.expand_dims(feature_6, -1)\n",
    "    \n",
    "    feature = np.concatenate([feature_1, feature_2, feature_3, feature_4, feature_5, feature_6], -1)\n",
    "    feature = np.reshape(feature, [len(set_count[set_num-1])*max_set[set_num-1], 6])\n",
    "    \n",
    "    label = np.array(label_padding_set(df['Label'], set_count, set_num))\n",
    "    label = np.reshape(label, [len(set_count[set_num-1])*max_set[set_num-1]])\n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    Set_data = []\n",
    "    set_train_count = []\n",
    "    set_test_count = []\n",
    "    with open(\"./crfsuite/set/Set_data.txt\", \"r\") as set_file:\n",
    "        Set_data = eval(set_file.readline())\n",
    "    with open(\"./crfsuite/set/set_train_count.txt\", \"r\") as set_file:\n",
    "        set_train_count = eval(set_file.readline())\n",
    "    with open(\"./crfsuite/set/set_test_count.txt\", \"r\") as set_file:\n",
    "        set_test_count = eval(set_file.readline())\n",
    "    max_num_train = max_num_set(set_train_count, set_total)\n",
    "    max_num_test = max_num_set(set_test_count, set_total)\n",
    "    max_set = []\n",
    "    for i in range(len(max_num_train)):\n",
    "        max_set.append(max(max_num_train[i], max_num_test[i]))\n",
    "    if DEBUG:\n",
    "        print(max_num_train)\n",
    "        print(max_num_test)\n",
    "        print(max_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    for num in range(set_total):\n",
    "        set_num = num + 1\n",
    "        # Load Train file & Test file\n",
    "        df = get_df(\"./crfsuite/set/Set-\"+str(set_num)+\"_train_raw.csv\")\n",
    "        max_num = max_set[set_num-1]\n",
    "        max_label = max(df['Label'])\n",
    "        feature_train, label_train = to_train_array_set(df, set_train_count, set_num)\n",
    "        page_num = int(len(feature_train)/max_num)\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            c1=0.1\n",
    "        )\n",
    "        feature_train = feature_train.tolist()\n",
    "        label_train = label_train.tolist()\n",
    "        X_train = [sent2features(feature_train)]\n",
    "        y_train = [sent2labels(label_train)]\n",
    "        \n",
    "        # Train\n",
    "        start = time.time()\n",
    "        crf.fit(X_train, y_train)\n",
    "        t += time.time()-start\n",
    "        \n",
    "        # Load Test file\n",
    "        df = get_df(\"./crfsuite/set/Set-\"+str(set_num)+\"_ytest_raw.csv\")\n",
    "        feature_test, label_test = to_train_array_set(df, set_test_count, set_num)\n",
    "        feature_test = feature_test.tolist()\n",
    "        label_test = label_test.tolist()\n",
    "        X_test = [sent2features(feature_test)]\n",
    "        page_test = int(len(feature_test)/max_num)\n",
    "            \n",
    "        # Prediction\n",
    "        labels = list(crf.classes_)\n",
    "        ts_start = time.time()\n",
    "        y_pred = crf.predict(X_test)\n",
    "        ts += time.time()-ts_start\n",
    "        y_pred = np.array(y_pred)\n",
    "        result = np.reshape(y_pred, [page_test, max_num])\n",
    "        result = result.astype(np.int64)\n",
    "        \n",
    "        # Read Col\n",
    "        col_type = []\n",
    "        with open(\"./set/Set-\"+str(set_num)+\"_coltype.txt\", \"r\") as file:\n",
    "            tmp = file.readline()\n",
    "            slot = eval(tmp)\n",
    "            col_type = slot\n",
    "            \n",
    "        # Output\n",
    "        Set = []\n",
    "        with open(\"./crfsuite/set/set-\"+str(set_num)+\".csv\", \"w\") as file: # Create prediction file\n",
    "            for col in col_type: # loop to write the Col type\n",
    "                file.write(col + \"\\t\")\n",
    "                if DEBUG:\n",
    "                    print(col + \"\\t\", end='')\n",
    "            if DEBUG:\n",
    "                print(\"\")\n",
    "            file.write(\"\\n\")\n",
    "            current_pos = 1\n",
    "            for page in tqdm(range(len(result))): # Loop each page\n",
    "                p_tmp = []\n",
    "                for cols in range(max_label+1):\n",
    "                    c_tmp = []\n",
    "                    for node in range(len(result[page])):\n",
    "                        r = result[page][node]\n",
    "                        if r == cols:\n",
    "                            c_tmp.append(node)\n",
    "                    p_tmp.append(c_tmp)\n",
    "                Set.append(p_tmp)\n",
    "            Set_tmp = Set.copy()\n",
    "            for page in range(len(Set_tmp)):\n",
    "                empty = False\n",
    "                col = []\n",
    "                for i in range(len(Set_tmp[page])):\n",
    "                    col.append(False)\n",
    "                col[0] = True\n",
    "                while(not empty):\n",
    "                    for cols in range(len(Set_tmp[page])):\n",
    "                        if len(Set_tmp[page][cols]) == 0:\n",
    "                            col[cols] = True\n",
    "                            if cols != 0:\n",
    "                                if DEBUG:\n",
    "                                    print(\"\\t\", end=\"\")\n",
    "                                file.write(\"\\t\")\n",
    "                        else:\n",
    "                            n = str(int(feature_test[page*max_num+Set_tmp[page][cols][0]][0]))\n",
    "                            if cols != 0:\n",
    "                                if DEBUG:\n",
    "                                    print(n+\"\\t\", end=\"\")\n",
    "                                file.write(n+\"\\t\")\n",
    "                            del Set_tmp[page][cols][0]\n",
    "                            if len(Set_tmp[page][cols]) == 0:\n",
    "                                col[cols] = True\n",
    "                        empty = True\n",
    "                        for i in col:\n",
    "                            if i == False:\n",
    "                                empty = False\n",
    "                                break\n",
    "                    if DEBUG:\n",
    "                        print(\"\\n\", end=\"\")\n",
    "                    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timef = open(\"./crfsuite/data/time_crf.txt\",\"w\")\n",
    "print(\"\\ntrain time:\"+str(t))\n",
    "timef.write(\"train:\"+str(t)+\"\\n\")\n",
    "print(\"test time:\"+str(ts))\n",
    "print(\"per page:\"+ str(float(ts)/page_c)+\"\\n\")\n",
    "timef.write(\"test:\"+str(ts)+\"\\n\")\n",
    "timef.write(\"per page:\"+ str(float(ts)/page_c)+\"\\n\")\n",
    "timef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S56 500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
