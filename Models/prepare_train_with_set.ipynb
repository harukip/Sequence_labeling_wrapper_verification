{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input file parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must indicated how many set are there in the TableA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_total = 0\n",
    "current_path = os.path.join(os.path.expanduser(\"~\"), \"jupyter\", \"web_verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rick/jupyter/web_verification\n"
     ]
    }
   ],
   "source": [
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train file create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the DCADE output TableA.txt and read page file to give each node data corresponding labels (column number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Opening:/home/rick/jupyter/web_verification/data/TableA.txt\n",
      "\n",
      "Generating:/home/rick/jupyter/web_verification/data/train_raw.txt\n",
      "\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "open page-0001.txt\n",
      "open page-0002.txt\n",
      "open page-0003.txt\n",
      "open page-0004.txt\n",
      "open page-0005.txt\n",
      "open page-0006.txt\n",
      "open page-0007.txt\n",
      "open page-0008.txt\n",
      "open page-0009.txt\n",
      "open page-0010.txt\n",
      "open page-0011.txt\n",
      "open page-0012.txt\n",
      "open page-0013.txt\n",
      "open page-0014.txt\n",
      "open page-0015.txt\n",
      "open page-0016.txt\n",
      "open page-0017.txt\n",
      "open page-0018.txt\n",
      "open page-0019.txt\n",
      "open page-0020.txt\n",
      "open page-0021.txt\n",
      "open page-0022.txt\n",
      "open page-0023.txt\n",
      "open page-0024.txt\n",
      "open page-0025.txt\n",
      "open page-0026.txt\n",
      "open page-0027.txt\n",
      "open page-0028.txt\n",
      "open page-0029.txt\n",
      "open page-0030.txt\n"
     ]
    }
   ],
   "source": [
    "table_name = os.path.join(current_path, \"data\", \"TableA.txt\")\n",
    "print(\"Table Opening:\" + table_name + \"\\n\")\n",
    "table_a = open(table_name, \"r\")\n",
    "output_name = os.path.join(current_path, \"data\", \"train_raw.txt\")\n",
    "print(\"Generating:\" + output_name + \"\\n\")\n",
    "\n",
    "Set_index = {}\n",
    "\n",
    "output = open(output_name, \"w\")\n",
    "output.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tPath\\tContent\\tLabel\\n\")\n",
    "\n",
    "line = table_a.readline()\n",
    "slot = line.rstrip(\"\\n\").split(\"\\t\") # Read Table line in line and split by \\t saved in slot.\n",
    "\n",
    "while(slot[0]!=\"ColType\"):\n",
    "    '''\n",
    "    Loop until we find the \"ColType\" in the table file to start generate training data.\n",
    "    '''\n",
    "    print(\"find coltype\")\n",
    "    line = table_a.readline()\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "col = []\n",
    "line = table_a.readline() # Read first line\n",
    "while(line != \"\"):\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    page_name = slot[0]\n",
    "    node_col = slot[1:] # Save each column's data in node_col\n",
    "    col = []\n",
    "    for i in node_col: # Split Same column data and save in list col\n",
    "        tmp = i.split(\" \")\n",
    "        col.append(tmp)\n",
    "    \n",
    "    current_page = 0\n",
    "    for pos in range(len(col)): # Loop all col num\n",
    "        if len(col[pos]) == 1 and not col[pos][0].isnumeric(): # Find \"X-X\" like sets\n",
    "            #print(\"Find : \"+col[pos][0])\n",
    "            current_page = col[pos][0].split(\"-\")[1]\n",
    "            current_page = int(current_page)\n",
    "            set_num = col[pos][0].split(\"-\")[0]\n",
    "            set_num = int(set_num)\n",
    "            if set_num not in Set_index.keys():\n",
    "                #print(\"Add new set in dict col num:\"+str(pos+1))\n",
    "                Set_index[set_num] = pos+1 # Record it in dict\n",
    "    \n",
    "    page_file = pd.read_csv(os.path.join(current_path, \"Output\", page_name), sep='\\t') # Read page file from DECADE Output file.\n",
    "    \n",
    "    col_name = []\n",
    "    for i in page_file.columns: # Save all column name\n",
    "        col_name.append(i)\n",
    "    \n",
    "    print(\"open \"+ page_name)\n",
    "    label_dict = {} # Define Dict of labels for each node\n",
    "    for leafnode in page_file[col_name[0]]: # Loop each node in page\n",
    "        for pos in range(len(col)): # Loop all col\n",
    "            if str(leafnode) in col[pos]: # if node is in this column\n",
    "                if leafnode not in label_dict.keys(): # and if this node not in dict save it\n",
    "                    label_dict[leafnode] = pos+1 # Shift one column for every node (zero is for empty).\n",
    "                #print(str(leafnode) + \"\\'s label: \" + str(pos))\n",
    "                break\n",
    "    \n",
    "    for set_count in range(set_total): # Loop every set and give each node a label, which is the column number of the set.\n",
    "        with open(os.path.join(current_path, \"data\", \"Set-\"+str(set_count+1)+\".txt\"), \"r\") as set_file:\n",
    "            line = set_file.readline()\n",
    "            slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            while(slot[0] != \"ColType\"):\n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            line = set_file.readline()\n",
    "            slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            while(line!=\"\"):\n",
    "                file_set_info = slot[0].split(\"-\")\n",
    "                file_set_num = set_count\n",
    "                file_set_page = int(file_set_info[1])\n",
    "                for node in slot[1:]:\n",
    "                    if not node.isnumeric():\n",
    "                        continue\n",
    "                    node = int(node)\n",
    "                    if file_set_page == current_page:\n",
    "                        label_dict[node] = Set_index[set_count+1]\n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    error = False\n",
    "    '''for i in range(max(label_dict.keys())+1):\n",
    "        if i not in label_dict:\n",
    "            error = True\n",
    "            print(i)'''\n",
    "    #print(label_dict)\n",
    "    #count = 0\n",
    "    data_list = [[], [], [], [], [], [], [], [], []]\n",
    "    for i in range(max(label_dict.keys())+1): # Loop each recorded node and output as train file\n",
    "        Leafnode = page_file[col_name[0]][i]\n",
    "        PTypeSetid = page_file[col_name[6]][i]\n",
    "        TypeSetid = page_file[col_name[7]][i]\n",
    "        Contentid = page_file[col_name[8]][i].split(\"-\")[1]\n",
    "        Pathid = page_file[col_name[9]][i]\n",
    "        SimSeqid = page_file[col_name[10]][i]\n",
    "        Path = page_file[col_name[2]][i]\n",
    "        Content = page_file[col_name[1]][i]\n",
    "        cols = [Leafnode, PTypeSetid, TypeSetid, Contentid, Pathid, SimSeqid, Path, Content]\n",
    "        for c in range(len(cols)):\n",
    "            output.write(str(cols[c]) + \"\\t\")\n",
    "            data_list[c].append(cols[c])\n",
    "        if i not in label_dict:\n",
    "            output.write(\"0\\n\")\n",
    "            data_list[len(cols)].append(0)\n",
    "        else:\n",
    "            output.write(str(label_dict[i]) + \"\\n\")\n",
    "            data_list[len(cols)].append(label_dict[i])\n",
    "    line = table_a.readline()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.transpose(np.array(data_list)), \n",
    "             columns=[\"Leafnode\", \"PTypeSet\", \"TypeSet\", \"Contentid\", \"Pathid\", \"Simseqid\", \"Path\", \"Content\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leafnode</th>\n",
       "      <th>PTypeSet</th>\n",
       "      <th>TypeSet</th>\n",
       "      <th>Contentid</th>\n",
       "      <th>Pathid</th>\n",
       "      <th>Simseqid</th>\n",
       "      <th>Path</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[HTML, HEAD, TITLE, #text]</td>\n",
       "      <td>Offshore Energy 2011 on LinkedIn Events</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[HTML, HEAD, LINK]</td>\n",
       "      <td>http://events-cdn.linkedin.com/stylesheets/sty...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[HTML, HEAD, LINK]</td>\n",
       "      <td>http://events-cdn.linkedin.com/stylesheets/api...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[HTML, BODY, DIV, DIV, H1, A, IMG]</td>\n",
       "      <td>http://static.linkedin.com/img/pic/pic_logo_11...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[HTML, BODY, DIV, DIV, H1, A]</td>\n",
       "      <td>http://www.linkedin.com/?trk=hb_logo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Leafnode PTypeSet TypeSet Contentid Pathid Simseqid  \\\n",
       "0        0        1      31      1801      0        0   \n",
       "1        1        3       4         2      1        0   \n",
       "2        2        3       4         3      1        0   \n",
       "3        3        3       4         4      2        1   \n",
       "4        4        3       4         5      2        2   \n",
       "\n",
       "                                 Path  \\\n",
       "0          [HTML, HEAD, TITLE, #text]   \n",
       "1                  [HTML, HEAD, LINK]   \n",
       "2                  [HTML, HEAD, LINK]   \n",
       "3  [HTML, BODY, DIV, DIV, H1, A, IMG]   \n",
       "4       [HTML, BODY, DIV, DIV, H1, A]   \n",
       "\n",
       "                                             Content Label  \n",
       "0            Offshore Energy 2011 on LinkedIn Events     1  \n",
       "1  http://events-cdn.linkedin.com/stylesheets/sty...     2  \n",
       "2  http://events-cdn.linkedin.com/stylesheets/api...     3  \n",
       "3  http://static.linkedin.com/img/pic/pic_logo_11...     4  \n",
       "4               http://www.linkedin.com/?trk=hb_logo     5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if not error:\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Set data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorded the node index that is in a set and saved it in file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(os.path.join(current_path, \"data\", \"Set_idx.txt\"), \"w\") as set_file:\n",
    "        set_file.write(str(Set_index))\n",
    "    print(Set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA file create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA file is for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Opening:/home/rick/jupyter/web_verification/data/GA.txt\n",
      "\n",
      "Generating:/home/rick/jupyter/web_verification/data/ytest_raw.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = os.path.join(current_path, \"data\", \"GA.txt\")\n",
    "print(\"Table Opening:\" + table_name + \"\\n\")\n",
    "table_a = open(table_name, \"r\")\n",
    "output_name = os.path.join(current_path, \"data\", \"ytest_raw.csv\")\n",
    "print(\"Generating:\" + output_name + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing file generation is same as training file generation, but give all the nodes label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open page-0001.txt\n",
      "open page-0002.txt\n",
      "open page-0003.txt\n",
      "open page-0004.txt\n",
      "open page-0005.txt\n",
      "open page-0006.txt\n",
      "open page-0007.txt\n",
      "open page-0008.txt\n",
      "open page-0009.txt\n",
      "open page-0010.txt\n",
      "open page-0011.txt\n",
      "open page-0012.txt\n",
      "open page-0013.txt\n",
      "open page-0014.txt\n",
      "open page-0015.txt\n",
      "open page-0016.txt\n",
      "open page-0017.txt\n",
      "open page-0018.txt\n",
      "open page-0019.txt\n",
      "open page-0020.txt\n",
      "open page-0021.txt\n",
      "open page-0022.txt\n",
      "open page-0023.txt\n",
      "open page-0024.txt\n",
      "open page-0025.txt\n",
      "open page-0026.txt\n",
      "open page-0027.txt\n",
      "open page-0028.txt\n",
      "open page-0029.txt\n",
      "open page-0030.txt\n"
     ]
    }
   ],
   "source": [
    "Set_index = {}\n",
    "output = open(output_name, \"w\")\n",
    "output.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tPath\\tContent\\tLabel\\n\")\n",
    "line = table_a.readline()\n",
    "slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "while(slot[0]!=\"ColType\"):\n",
    "    print(\"find coltype\")\n",
    "    line = table_a.readline()\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "line = table_a.readline() # Read\n",
    "while(line != \"\"):\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    page_name = slot[0]\n",
    "    if slot[0]==\"\":\n",
    "        break\n",
    "    page_file = pd.read_csv(os.path.join(current_path, \"Output\", page_name), sep='\\t')\n",
    "    col_name = []\n",
    "    for i in page_file.columns:\n",
    "        col_name.append(i)\n",
    "    print(\"open \"+ page_name)\n",
    "    label_dict = {}\n",
    "    for node in range(len(page_file[col_name[0]])):\n",
    "        Leafnode = page_file[col_name[0]][node]\n",
    "        PTypeSetid = page_file[col_name[6]][node]\n",
    "        TypeSetid = page_file[col_name[7]][node]\n",
    "        Contentid = page_file[col_name[8]][node].split(\"-\")[1]\n",
    "        Pathid = page_file[col_name[9]][node]\n",
    "        SimSeqid = page_file[col_name[10]][node]\n",
    "        Path = page_file[col_name[2]][node]\n",
    "        Content = page_file[col_name[1]][node]\n",
    "        output.write(str(Leafnode) + \"\\t\")\n",
    "        output.write(str(PTypeSetid) + \"\\t\")\n",
    "        output.write(str(TypeSetid) + \"\\t\")\n",
    "        output.write(str(Contentid) + \"\\t\")\n",
    "        output.write(str(Pathid) + \"\\t\")\n",
    "        output.write(str(SimSeqid) + \"\\t\")\n",
    "        output.write(str(Path) + \"\\t\")\n",
    "        output.write(str(Content) + \"\\t\")\n",
    "        output.write(str(0) + \"\\n\")\n",
    "    line = table_a.readline() # Read\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
