{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train file create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the DCADE output TableA.txt and read page file to give each node data corresponding labels (column number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_file_generate(set_total, current_path):\n",
    "    table_name = os.path.join(current_path, \"data\", \"TableA.txt\")\n",
    "    print(\"Table Opening:\" + table_name + \"\\n\")\n",
    "    table_a = open(table_name, \"r\")\n",
    "    output_name = os.path.join(current_path, \"data\", \"train_raw.txt\")\n",
    "    print(\"Generating:\" + output_name + \"\\n\")\n",
    "\n",
    "    Set_index = {}\n",
    "\n",
    "    output = open(output_name, \"w\")\n",
    "    output.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tPath\\tContent\\tLabel\\n\")\n",
    "\n",
    "    line = table_a.readline()\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\") # Read Table line in line and split by \\t saved in slot.\n",
    "\n",
    "    while(slot[0]!=\"ColType\"):\n",
    "        '''\n",
    "        Loop until we find the \"ColType\" in the table file to start generate training data.\n",
    "        '''\n",
    "        line = table_a.readline()\n",
    "        slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    print(\"find coltype\")\n",
    "    col = []\n",
    "    line = table_a.readline() # Read first line\n",
    "    while(line != \"\"):\n",
    "        slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        page_name = slot[0]\n",
    "        node_col = slot[1:] # Save each column's data in node_col\n",
    "        col = []\n",
    "        for i in node_col: # Split Same column data and save in list col\n",
    "            tmp = i.split(\" \")\n",
    "            col.append(tmp)\n",
    "\n",
    "        current_page = 0\n",
    "        for pos in range(len(col)): # Loop all col num\n",
    "            if len(col[pos]) == 1 and not col[pos][0].isnumeric(): # Find \"X-X\" like sets\n",
    "                #print(\"Find : \"+col[pos][0])\n",
    "                current_page = col[pos][0].split(\"-\")[1]\n",
    "                current_page = int(current_page)\n",
    "                set_num = col[pos][0].split(\"-\")[0]\n",
    "                set_num = int(set_num)\n",
    "                if set_num not in Set_index.keys():\n",
    "                    #print(\"Add new set in dict col num:\"+str(pos+1))\n",
    "                    Set_index[set_num] = pos+1 # Record it in dict\n",
    "\n",
    "        page_file = pd.read_csv(os.path.join(current_path, \"Output\", page_name), sep='\\t') # Read page file from DECADE Output file.\n",
    "\n",
    "        col_name = []\n",
    "        for i in page_file.columns: # Save all column name\n",
    "            col_name.append(i)\n",
    "\n",
    "        #print(\"open \"+ page_name)\n",
    "        label_dict = {} # Define Dict of labels for each node\n",
    "        for leafnode in page_file[col_name[0]]: # Loop each node in page\n",
    "            for pos in range(len(col)): # Loop all col\n",
    "                if str(leafnode) in col[pos]: # if node is in this column\n",
    "                    if leafnode not in label_dict.keys(): # and if this node not in dict save it\n",
    "                        label_dict[leafnode] = pos+1 # Shift one column for every node (zero is for empty).\n",
    "                    #print(str(leafnode) + \"\\'s label: \" + str(pos))\n",
    "                    break\n",
    "\n",
    "        for set_count in range(set_total): # Loop every set and give each node a label, which is the column number of the set.\n",
    "            with open(os.path.join(current_path, \"data\", \"Set-\"+str(set_count+1)+\".txt\"), \"r\") as set_file:\n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "                while(slot[0] != \"ColType\"):\n",
    "                    line = set_file.readline()\n",
    "                    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                while(line!=\"\"):\n",
    "                    file_set_info = slot[0].split(\"-\")\n",
    "                    file_set_num = set_count\n",
    "                    file_set_page = int(file_set_info[1])\n",
    "                    for node in slot[1:]:\n",
    "                        if not node.isnumeric():\n",
    "                            continue\n",
    "                        node = int(node)\n",
    "                        if file_set_page == current_page:\n",
    "                            label_dict[node] = Set_index[set_count+1]\n",
    "                    line = set_file.readline()\n",
    "                    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        error = False\n",
    "        '''for i in range(max(label_dict.keys())+1):\n",
    "            if i not in label_dict:\n",
    "                error = True\n",
    "                print(i)'''\n",
    "        #print(label_dict)\n",
    "        #count = 0\n",
    "        data_list = [[], [], [], [], [], [], [], [], []]\n",
    "        for i in range(max(label_dict.keys())+1): # Loop each recorded node and output as train file\n",
    "            Leafnode = page_file[col_name[0]][i]\n",
    "            PTypeSetid = page_file[col_name[6]][i]\n",
    "            TypeSetid = page_file[col_name[7]][i]\n",
    "            Contentid = page_file[col_name[8]][i].split(\"-\")[1]\n",
    "            Pathid = page_file[col_name[9]][i]\n",
    "            SimSeqid = page_file[col_name[10]][i]\n",
    "            Path = page_file[col_name[2]][i]\n",
    "            Content = page_file[col_name[1]][i]\n",
    "            cols = [Leafnode, PTypeSetid, TypeSetid, Contentid, Pathid, SimSeqid, Path, Content]\n",
    "            for c in range(len(cols)):\n",
    "                output.write(str(cols[c]) + \"\\t\")\n",
    "                data_list[c].append(cols[c])\n",
    "            if i not in label_dict:\n",
    "                output.write(\"0\\n\")\n",
    "                data_list[len(cols)].append(0)\n",
    "            else:\n",
    "                output.write(str(label_dict[i]) + \"\\n\")\n",
    "                data_list[len(cols)].append(label_dict[i])\n",
    "        line = table_a.readline()\n",
    "    output.close()\n",
    "    data = pd.DataFrame(np.transpose(np.array(data_list)), \n",
    "                 columns=[\"Leafnode\", \"PTypeSet\", \"TypeSet\", \"Contentid\", \"Pathid\", \"Simseqid\", \"Path\", \"Content\", \"Label\"])\n",
    "    return data, Set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rick/jupyter/web_verification\n",
      "Table Opening:/home/rick/jupyter/web_verification/data/TableA.txt\n",
      "\n",
      "Generating:/home/rick/jupyter/web_verification/data/train_raw.txt\n",
      "\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "find coltype\n",
      "open page-0001.txt\n",
      "open page-0002.txt\n",
      "open page-0003.txt\n",
      "open page-0004.txt\n",
      "open page-0005.txt\n",
      "open page-0006.txt\n",
      "open page-0007.txt\n",
      "open page-0008.txt\n",
      "open page-0009.txt\n",
      "open page-0010.txt\n",
      "open page-0011.txt\n",
      "open page-0012.txt\n",
      "open page-0013.txt\n",
      "open page-0014.txt\n",
      "open page-0015.txt\n",
      "open page-0016.txt\n",
      "open page-0017.txt\n",
      "open page-0018.txt\n",
      "open page-0019.txt\n",
      "open page-0020.txt\n",
      "open page-0021.txt\n",
      "open page-0022.txt\n",
      "open page-0023.txt\n",
      "open page-0024.txt\n",
      "open page-0025.txt\n",
      "open page-0026.txt\n",
      "open page-0027.txt\n",
      "open page-0028.txt\n",
      "open page-0029.txt\n",
      "open page-0030.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    set_total = 0\n",
    "    current_path = os.path.join(os.path.expanduser(\"~\"), \"jupyter\", \"web_verification\")\n",
    "    print(current_path)\n",
    "    data, Set_index = train_file_generate(set_total, current_path)\n",
    "    if set_total > 0:\n",
    "        with open(os.path.join(current_path, \"data\", \"Set_idx.txt\"), \"w\") as set_file:\n",
    "            set_file.write(str(Set_index))\n",
    "        print(Set_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
