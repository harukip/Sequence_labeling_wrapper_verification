{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function, absolute_import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from crflayer import CRF\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_crfsuite import metrics\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_total = 6\n",
    "# How many Set\n",
    "BATCH_SIZE = 1      # Training bath size\n",
    "VAL_BATCH_SIZE = 1  # Validation batch size\n",
    "\n",
    "DEBUG = False        # Print element\n",
    "path_max_len = 30    # padding length\n",
    "path_emb_size = 5    # embedding size\n",
    "\n",
    "con_max_len = 50    # padding length\n",
    "con_emb_size = 5    # embedding size\n",
    "\n",
    "feature_emb_size = 3\n",
    "\n",
    "EPOCHS = 10000        # Train epochs\n",
    "conv_num = 5        # First cnn filter num\n",
    "#max_num = 206       # How many nodes should pad\n",
    "UNTIL_LOSS = 0.001    # When achieve loss then stop\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.004) # Set learning rate\n",
    "NO_IMPROVE = 2     # Stop when no improve for epochs\n",
    "OOM_Split = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tokenizer to convert words to encoding for embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = tf.keras.preprocessing.text.Tokenizer(num_words=None)\n",
    "tokenizer_content = tf.keras.preprocessing.text.Tokenizer(num_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_num(data):\n",
    "    '''\n",
    "    To generate a list of numbers of nodes that each page have\n",
    "    '''\n",
    "    count = False\n",
    "    num_list = []\n",
    "    for index in range(len(data)):\n",
    "        if data[index] == 0 and count != False:\n",
    "            num_list.append(data[index-1] + 1)\n",
    "        else:\n",
    "            count = True\n",
    "    num_list.append(data[len(data) - 1] + 1)\n",
    "    count = 0\n",
    "    index_list = []\n",
    "    for i in num_list:\n",
    "        if count == 0:\n",
    "            index_list.append(i - 1)\n",
    "            count += 1\n",
    "        else:\n",
    "            index_list.append(index_list[count - 1] + i)\n",
    "            count += 1\n",
    "    return num_list, index_list\n",
    "\n",
    "\n",
    "def node_data(data, num):\n",
    "    '''\n",
    "    Padding the data with zero when that page is less than max_num leafnode\n",
    "    '''\n",
    "    output = []\n",
    "    count = 0\n",
    "    for page_num in num:\n",
    "        tmp = []\n",
    "        page = 0\n",
    "        if page_num == max_num:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            page += 1\n",
    "        else:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            for i in range(max_num - page_num):\n",
    "                tmp.append(99999)\n",
    "            page += 1\n",
    "        output.append(tmp)\n",
    "    return output\n",
    "\n",
    "def label_padding(data, num):\n",
    "    '''\n",
    "    Padding the labels with zero when that page is less than max_num leafnode\n",
    "    '''\n",
    "    output = []\n",
    "    count = 0\n",
    "    for page_num in num:\n",
    "        tmp = []\n",
    "        page = 0\n",
    "        if page_num == max_num:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            page += 1\n",
    "        else:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            for i in range(max_num - page_num):\n",
    "                tmp.append(0) # Pad label with 0\n",
    "            page += 1\n",
    "        output.append(tmp)\n",
    "    return output\n",
    "\n",
    "\n",
    "def node_emb(data, num, pad_len):\n",
    "    '''\n",
    "    Padding the embedding with empty when that page is less than max_num leafnode.\n",
    "    '''\n",
    "    output = []\n",
    "    count = 0\n",
    "    tmp2 = []\n",
    "    for j in range(pad_len):\n",
    "        tmp2.append(0.0)\n",
    "    for page_num in num:\n",
    "        tmp = []\n",
    "        page = 0\n",
    "        if page_num == max_num:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            page += 1\n",
    "        else:\n",
    "            for i in range(page_num):\n",
    "                tmp.append(data[count])\n",
    "                count += 1\n",
    "            for i in range(max_num - page_num):\n",
    "                tmp.append(tmp2)\n",
    "            page += 1\n",
    "        output.append(tmp)\n",
    "    return output\n",
    "\n",
    "def get_df(path):\n",
    "    '''\n",
    "    Read csv file and return pandas dataframe.\n",
    "    '''\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    return df\n",
    "    \n",
    "\n",
    "def load_data_csv(df):\n",
    "    '''\n",
    "    Load the pandas dataframe and convert it to numpy array for train and test.\n",
    "    '''\n",
    "    path_encoded = tokenizer_path.texts_to_sequences(df['Path'])\n",
    "    df['Content'] = df['Content'].str.replace('/|\\.|\\?|:|=|,|<|>|&|@|\\+|-|#|~|\\|', ' ')\n",
    "    df['Content'] = df['Content'].astype(str)\n",
    "    content_encoded = tokenizer_content.texts_to_sequences(df['Content'])\n",
    "    path_pad = tf.keras.preprocessing.sequence.pad_sequences(path_encoded, path_max_len, padding='post')\n",
    "    content_pad = tf.keras.preprocessing.sequence.pad_sequences(content_encoded, con_max_len, padding='post')\n",
    "    if DEBUG:\n",
    "        print(path_pad.shape)\n",
    "        print(content_pad.shape)\n",
    "    num, index = node_num(df['Leafnode'])\n",
    "    path = np.array(node_emb(path_pad, num, path_max_len))\n",
    "    content = np.array(node_emb(content_pad, num, con_max_len))\n",
    "    if DEBUG:\n",
    "        print(path.shape)\n",
    "        print(content.shape)\n",
    "    feature_1 = np.array(node_data(df['Leafnode'], num))\n",
    "    df.drop(['Leafnode'], axis=1)\n",
    "    feature_2 = np.array(node_data(df['PTypeSet'], num))\n",
    "    df.drop(['PTypeSet'], axis=1)\n",
    "    feature_3 = np.array(node_data(df['TypeSet'], num))\n",
    "    df.drop(['TypeSet'], axis=1)\n",
    "    feature_4 = np.array(node_data(df['Contentid'], num))\n",
    "    df.drop(['Contentid'], axis=1)\n",
    "    feature_5 = np.array(node_data(df['Pathid'], num))\n",
    "    df.drop(['Pathid'], axis=1)\n",
    "    feature_6 = np.array(node_data(df['Simseqid'], num))\n",
    "    df.drop(['Simseqid'], axis=1)\n",
    "    \n",
    "    label_array = np.array(label_padding(df['Label'], num))\n",
    "    m_label = df['Label'].max()\n",
    "    df.drop(['Label'], axis=1)\n",
    "    label = []\n",
    "    path_arr = []\n",
    "    content_arr = []\n",
    "    for pages in tqdm(range(len(label_array))): # Loop each page\n",
    "        page = []\n",
    "        path_page = []\n",
    "        content_page = []\n",
    "        for node in range(len(label_array[pages])): # Loop each node\n",
    "            node_label = []\n",
    "            for label_t in range(max_label + 1): # Loop each label and a additional empty label ex.1~142 0 is empty\n",
    "                if label_t == label_array[pages][node]:\n",
    "                    node_label.append(1.0)\n",
    "                else:\n",
    "                    node_label.append(0.0)\n",
    "            page.append(node_label)\n",
    "            path_page.append(path[pages][node])\n",
    "            content_page.append(content[pages][node])\n",
    "        label.append(page)\n",
    "        path_arr.append(path_page)\n",
    "        content_arr.append(content_page)\n",
    "    label = np.array(label)\n",
    "    path_arr = np.array(path_arr)\n",
    "    content_arr = np.array(content_arr)\n",
    "    path_arr = np.reshape(path_arr, [len(label_array), max_num, path_max_len])\n",
    "    content_arr = np.reshape(content_arr, [len(label_array), max_num, con_max_len])\n",
    "    label = np.reshape(label, [len(label_array), max_num, max_label+1])\n",
    "    \n",
    "    # OOM part\n",
    "    feature_1 = np.reshape(feature_1, [-1, int(max_num/OOM_Split)])\n",
    "    feature_2 = np.reshape(feature_2, [-1, int(max_num/OOM_Split)])\n",
    "    feature_3 = np.reshape(feature_3, [-1, int(max_num/OOM_Split)])\n",
    "    feature_4 = np.reshape(feature_4, [-1, int(max_num/OOM_Split)])\n",
    "    feature_5 = np.reshape(feature_5, [-1, int(max_num/OOM_Split)])\n",
    "    feature_6 = np.reshape(feature_6, [-1, int(max_num/OOM_Split)])\n",
    "    label = np.reshape(label, [-1, int(max_num/OOM_Split), max_label+1])\n",
    "    path_arr = np.reshape(path_arr, [-1, int(max_num/OOM_Split), path_max_len])\n",
    "    content_arr = np.reshape(content_arr, [-1, int(max_num/OOM_Split), con_max_len])\n",
    "    \n",
    "    return feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, path_arr, content_arr, label, m_label\n",
    "\n",
    "\n",
    "def load_data_num(path, istrain):\n",
    "    '''\n",
    "    Get the max num of leafnodes and return.\n",
    "    '''\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    num, index = node_num(df['Leafnode'])\n",
    "    if istrain:\n",
    "        max_label = df['Label'].max()\n",
    "        return max(num), max_label\n",
    "    else:\n",
    "        return max(num)\n",
    "\n",
    "\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    Draw the figure of train.\n",
    "    '''\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        f1 = plt.figure(1)\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc')\n",
    "\n",
    "        f2 = plt.figure(2)\n",
    "        plt.plot(iters, self.losses[loss_type], 'r', label='train loss')\n",
    "        plt.plot(iters, self.val_loss[loss_type], 'b', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('loss')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train until loss Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    Early stop when training value less than setting value.\n",
    "    '''\n",
    "    def __init__(self, monitor='loss', value=UNTIL_LOSS, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check max_num in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the train file and test file to check max number of nodes for each page to give the number for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_train, max_label_train = load_data_num(\"./data/train_raw.csv\", True)\n",
    "max_num_test = load_data_num(\"./data/ytest_raw.csv\", False)\n",
    "max_num = max(max_num_train, max_num_test)\n",
    "if max_num%OOM_Split != 0: # Let max num can be spilt into 10.\n",
    "    max_num += OOM_Split - max_num%OOM_Split\n",
    "if DEBUG:\n",
    "    print(max_num_train)\n",
    "    print(max_num_test)\n",
    "    print(max_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Set index File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Set_idx file to check which label is a Set in the training file generated by the training file generation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set_dict={}\n",
    "if set_total > 0:\n",
    "    Set_dict = {}\n",
    "    with open(\"./data/Set_idx.txt\", \"r\") as set_file:\n",
    "        Set_dict = eval(set_file.readline())\n",
    "    col_set_dict = dict(map(reversed, Set_dict.items()))\n",
    "    if DEBUG:\n",
    "        print(Set_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Training file and make tokenizer to fit on Path and Content to get the encoding for words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "max_label = max_label_train\n",
    "df = get_df(\"./data/train_raw.csv\")\n",
    "tokenizer_path.fit_on_texts(df['Path'])\n",
    "tokenizer_content.fit_on_texts(df['Content'].astype(str))\n",
    "path_word_size = len(tokenizer_path.index_docs)\n",
    "con_word_size = len(tokenizer_content.index_docs)\n",
    "feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6, path_train, content_train, label_train, out_train = load_data_csv(df)\n",
    "crf = CRF(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(feature_train_1.shape)\n",
    "    print(label_train.shape)\n",
    "    print(path_word_size)\n",
    "    print(con_word_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    '''\n",
    "    Model definition for our experiments using tensorflow keras.\n",
    "    '''\n",
    "    path_input = tf.keras.Input(shape=(int(max_num/OOM_Split), path_max_len), name='Path_emb_input')\n",
    "    content_input = tf.keras.Input(shape=(int(max_num/OOM_Split), con_max_len), name='Content_emb_input')\n",
    "    feature_input_1 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input1')\n",
    "    feature_input_2 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input2')\n",
    "    feature_input_3 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input3')\n",
    "    feature_input_4 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input4')\n",
    "    feature_input_5 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input5')\n",
    "    feature_input_6 = tf.keras.Input(shape=(int(max_num/OOM_Split),), name='Feature_input6')\n",
    "    \n",
    "    path_f = tf.keras.layers.Flatten()(path_input)\n",
    "    content_f = tf.keras.layers.Flatten()(content_input)\n",
    "    \n",
    "    path_emb = tf.keras.layers.Embedding(path_word_size+1, path_emb_size)(path_f)\n",
    "    content_emb = tf.keras.layers.Embedding(con_word_size+1, con_emb_size)(content_f)\n",
    "    f_1_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_1)\n",
    "    f_2_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_2)\n",
    "    f_3_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_3)\n",
    "    f_4_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_4)\n",
    "    f_5_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_5)\n",
    "    f_6_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_6)\n",
    "    \n",
    "    path_emb = tf.reshape(path_emb, [-1, int(max_num/OOM_Split), path_max_len*path_emb_size])\n",
    "    content_emb = tf.reshape(content_emb, [-1, int(max_num/OOM_Split), con_max_len*con_emb_size])\n",
    "    \n",
    "    path_emb = tf.expand_dims(path_emb, -1)\n",
    "    content_emb = tf.expand_dims(content_emb, -1)\n",
    "    \n",
    "    path_feature = tf.keras.layers.Conv2D(conv_num, kernel_size=(3,  path_max_len*path_emb_size), strides=(1, path_max_len*path_emb_size), name='Conv_for_Path_emb', padding='same')(path_emb)\n",
    "    content_feature = tf.keras.layers.Conv2D(conv_num, kernel_size=(3, con_max_len*con_emb_size), strides=(1, con_max_len*con_emb_size), name='Conv_for_Content_emb', padding='same')(content_emb)\n",
    "    \n",
    "    path = tf.reshape(path_feature, [-1, conv_num])\n",
    "    content = tf.reshape(content_feature, [-1, conv_num])\n",
    "    \n",
    "    f_1_emb = tf.reshape(f_1_emb, [-1, feature_emb_size])\n",
    "    f_2_emb = tf.reshape(f_2_emb, [-1, feature_emb_size])\n",
    "    f_3_emb = tf.reshape(f_3_emb, [-1, feature_emb_size])\n",
    "    f_4_emb = tf.reshape(f_4_emb, [-1, feature_emb_size])\n",
    "    f_5_emb = tf.reshape(f_5_emb, [-1, feature_emb_size])\n",
    "    f_6_emb = tf.reshape(f_6_emb, [-1, feature_emb_size])\n",
    "\n",
    "    combine = tf.keras.layers.concatenate([path, content, f_1_emb, f_2_emb, f_3_emb, f_4_emb, f_5_emb, f_6_emb], -1)\n",
    "    d = combine\n",
    "    d = tf.keras.layers.Dense(max_label+1)(d)\n",
    "    d = tf.reshape(d, [-1, int(max_num/OOM_Split), max_label+1])\n",
    "    output = crf(d)\n",
    "    output = tf.reshape(output, [-1, int(max_num/OOM_Split), max_label+1])\n",
    "    model = tf.keras.Model(inputs=[path_input, content_input, feature_input_1, feature_input_2, feature_input_3, feature_input_4, feature_input_5, feature_input_6], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model with parameters (loss, optimizer and metrics), and set up the early stop callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Path_emb_input (InputLayer)     [(None, 636, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Content_emb_input (InputLayer)  [(None, 636, 50)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 19080)        0           Path_emb_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 31800)        0           Content_emb_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 19080, 5)     145         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 31800, 5)     55955       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 636, 150)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 636, 250)]   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 636, 150, 1) 0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 636, 250, 1) 0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input1 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input2 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input3 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input4 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input5 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_input6 (InputLayer)     [(None, 636)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv_for_Path_emb (Conv2D)      (None, 636, 1, 5)    2255        tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_for_Content_emb (Conv2D)   (None, 636, 1, 5)    3755        tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 636, 3)       300000      Feature_input1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 636, 3)       300000      Feature_input2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 636, 3)       300000      Feature_input3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 636, 3)       300000      Feature_input4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 636, 3)       300000      Feature_input5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 636, 3)       300000      Feature_input6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 5)]          0           Conv_for_Path_emb[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 5)]          0           Conv_for_Content_emb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, 3)]          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, 3)]          0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 3)]          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 3)]          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 3)]          0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 3)]          0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28)           0           tf_op_layer_Reshape_2[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_3[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_4[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_5[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_6[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_7[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_8[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1022)         29638       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_10 (TensorF [(None, 636, 1022)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, 636, 1022)    1044484     tf_op_layer_Reshape_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_11 (TensorF [(None, 636, 1022)]  0           crf[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 2,936,232\n",
      "Trainable params: 2,936,232\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.compile(\n",
    "    loss=crf.loss,\n",
    "    optimizer=opt,\n",
    "    metrics=[crf.accuracy]\n",
    ")\n",
    "print(model.summary())\n",
    "history = LossHistory()\n",
    "stop_when_no_improve = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=0, patience = NO_IMPROVE, restore_best_weights=True)\n",
    "until_loss = EarlyStoppingByLossVal(monitor='loss', value=UNTIL_LOSS, verbose=1)\n",
    "callbacks = [history, stop_when_no_improve, until_loss]\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training and recording the time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples\n",
      "Epoch 1/10000\n",
      "60/60 [==============================] - 33s 551ms/sample - loss: 3993.2780 - accuracy: 0.0341\n",
      "Epoch 2/10000\n",
      "60/60 [==============================] - 27s 447ms/sample - loss: 2296.4267 - accuracy: 0.2838\n",
      "Epoch 3/10000\n",
      "60/60 [==============================] - 27s 447ms/sample - loss: 694.4974 - accuracy: 0.7126\n",
      "Epoch 4/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 206.1778 - accuracy: 0.8343\n",
      "Epoch 5/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 92.3667 - accuracy: 0.8787\n",
      "Epoch 6/10000\n",
      "60/60 [==============================] - 27s 447ms/sample - loss: 52.0867 - accuracy: 0.9023\n",
      "Epoch 7/10000\n",
      "60/60 [==============================] - 26s 440ms/sample - loss: 32.5945 - accuracy: 0.9263\n",
      "Epoch 8/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 23.3598 - accuracy: 0.9387\n",
      "Epoch 9/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 18.2710 - accuracy: 0.9417\n",
      "Epoch 10/10000\n",
      "60/60 [==============================] - 27s 449ms/sample - loss: 13.9827 - accuracy: 0.9462\n",
      "Epoch 11/10000\n",
      "60/60 [==============================] - 26s 441ms/sample - loss: 10.3991 - accuracy: 0.9548\n",
      "Epoch 12/10000\n",
      "60/60 [==============================] - 26s 435ms/sample - loss: 8.2879 - accuracy: 0.9576\n",
      "Epoch 13/10000\n",
      "60/60 [==============================] - 26s 431ms/sample - loss: 6.9080 - accuracy: 0.9599\n",
      "Epoch 14/10000\n",
      "60/60 [==============================] - 27s 448ms/sample - loss: 6.2899 - accuracy: 0.9609\n",
      "Epoch 15/10000\n",
      "60/60 [==============================] - 26s 439ms/sample - loss: 5.1450 - accuracy: 0.9623\n",
      "Epoch 16/10000\n",
      "60/60 [==============================] - 26s 435ms/sample - loss: 4.9668 - accuracy: 0.9644\n",
      "Epoch 17/10000\n",
      "60/60 [==============================] - 27s 442ms/sample - loss: 3.9419 - accuracy: 0.9660\n",
      "Epoch 18/10000\n",
      "60/60 [==============================] - 27s 448ms/sample - loss: 3.7001 - accuracy: 0.9679\n",
      "Epoch 19/10000\n",
      "60/60 [==============================] - 26s 440ms/sample - loss: 3.0243 - accuracy: 0.9683\n",
      "Epoch 20/10000\n",
      "60/60 [==============================] - 26s 437ms/sample - loss: 2.6519 - accuracy: 0.9709\n",
      "Epoch 21/10000\n",
      "60/60 [==============================] - 26s 438ms/sample - loss: 2.4110 - accuracy: 0.9709\n",
      "Epoch 22/10000\n",
      "60/60 [==============================] - 27s 445ms/sample - loss: 2.1968 - accuracy: 0.9719\n",
      "Epoch 23/10000\n",
      "60/60 [==============================] - 26s 438ms/sample - loss: 2.0513 - accuracy: 0.9713\n",
      "Epoch 24/10000\n",
      "60/60 [==============================] - 26s 433ms/sample - loss: 1.8299 - accuracy: 0.9724\n",
      "Epoch 25/10000\n",
      "60/60 [==============================] - 26s 439ms/sample - loss: 1.7748 - accuracy: 0.9727\n",
      "Epoch 26/10000\n",
      "60/60 [==============================] - 27s 448ms/sample - loss: 1.6391 - accuracy: 0.9731\n",
      "Epoch 27/10000\n",
      "60/60 [==============================] - 26s 441ms/sample - loss: 1.4742 - accuracy: 0.9731\n",
      "Epoch 28/10000\n",
      "60/60 [==============================] - 26s 434ms/sample - loss: 1.3486 - accuracy: 0.9741\n",
      "Epoch 29/10000\n",
      "60/60 [==============================] - 27s 446ms/sample - loss: 1.2793 - accuracy: 0.9747\n",
      "Epoch 30/10000\n",
      "60/60 [==============================] - 27s 446ms/sample - loss: 1.1542 - accuracy: 0.9748\n",
      "Epoch 31/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 1.0915 - accuracy: 0.9759\n",
      "Epoch 32/10000\n",
      "60/60 [==============================] - 26s 436ms/sample - loss: 1.0290 - accuracy: 0.9753\n",
      "Epoch 33/10000\n",
      "60/60 [==============================] - 26s 441ms/sample - loss: 0.9452 - accuracy: 0.9761\n",
      "Epoch 34/10000\n",
      "60/60 [==============================] - 27s 446ms/sample - loss: 0.8866 - accuracy: 0.9760\n",
      "Epoch 35/10000\n",
      "60/60 [==============================] - 26s 433ms/sample - loss: 0.8267 - accuracy: 0.9765\n",
      "Epoch 36/10000\n",
      "60/60 [==============================] - 26s 435ms/sample - loss: 0.7723 - accuracy: 0.9767\n",
      "Epoch 37/10000\n",
      "60/60 [==============================] - 26s 441ms/sample - loss: 0.7330 - accuracy: 0.9769\n",
      "Epoch 38/10000\n",
      "60/60 [==============================] - 27s 444ms/sample - loss: 1.1088 - accuracy: 0.9772\n",
      "Epoch 39/10000\n",
      "60/60 [==============================] - 26s 437ms/sample - loss: 0.8237 - accuracy: 0.9768\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit([path_train, content_train, feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6], label_train, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True, batch_size=BATCH_SIZE)\n",
    "t = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the training accuracy-epochs and loss-epochs graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tokenizer data and model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save_weights(\"./crf/data/cnn-crf.h5\")\n",
    "# saving\n",
    "with open(\"./crf/data/tokenizer_path.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer_path, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"./crf/data/tokenizer_content.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer_content, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and tokenizer back from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = get_model()\n",
    "model.compile(\n",
    "    loss=crf.loss,\n",
    "    optimizer=opt,\n",
    "    metrics=[crf.accuracy]\n",
    ")\n",
    "model.load_weights(\"./crf/data/cnn-crf.h5\")\n",
    "# loading\n",
    "with open('./crf/data/tokenizer_path.pickle', 'rb') as handle:\n",
    "    tokenizer_path = pickle.load(handle)\n",
    "with open('./crf/data/tokenizer_content.pickle', 'rb') as handle:\n",
    "    tokenizer_content = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_df(\"./data/ytest_raw.csv\")\n",
    "feature_test_1, feature_test_2, feature_test_3, feature_test_4, feature_test_5, feature_test_6, path_test, content_test, a, b = load_data_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(max_num)\n",
    "    print(feature_test_1.shape)\n",
    "    print(path_test.shape)\n",
    "    print(path_word_size)\n",
    "    print(con_word_size)\n",
    "path_word_size = len(tokenizer_path.index_docs)\n",
    "con_word_size = len(tokenizer_content.index_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test file and record the testing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_start = time.time()\n",
    "predictions = model.predict([path_test, content_test, feature_test_1, feature_test_2, feature_test_3, feature_test_4, feature_test_5, feature_test_6], batch_size=VAL_BATCH_SIZE)\n",
    "ts = time.time()-ts_start\n",
    "predictions = np.reshape(predictions, [-1, max_num, max_label+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(feature_test_1[0][0])\n",
    "    print(path_test[0][0])\n",
    "    print(content_test[0][0])\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output & Turn predict back to label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick maximum argument label as prediction and save in result list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for page in range(predictions.shape[0]):\n",
    "    tmp = []\n",
    "    for node in range(max_num):\n",
    "        tmp.append(np.argmax(predictions[page][node]))\n",
    "    result.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Column Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Column type from TableA for file ColType output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_type = []\n",
    "with open(\"./data/TableA.txt\", \"r\") as file:\n",
    "    line = file.readline()\n",
    "    slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    while(slot[0]!=\"ColType\"):\n",
    "        line = file.readline()\n",
    "        slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    col_type = slot[1:]\n",
    "if DEBUG:\n",
    "    print(col_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File prediction output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the prediction.csv file for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Set_data = []\n",
    "with open(\"./crf/data/predictions.csv\", \"w\") as file: # Create prediction file\n",
    "    for col in col_type: # loop to write the Col type\n",
    "        file.write(col + \"\\t\")\n",
    "        if DEBUG:\n",
    "            print(col + \"\\t\", end='')\n",
    "    file.write(\"\\n\")\n",
    "    for page in tqdm(range(predictions.shape[0])): # Loop each page\n",
    "        sets = []\n",
    "        for label in range(label_train.shape[2] + 1): # Loop whole label\n",
    "            if DEBUG:\n",
    "                print(\"Label: \" + str(label))\n",
    "            if label == 0:\n",
    "                continue\n",
    "            empty = True\n",
    "            isset = False\n",
    "            data = []\n",
    "            for node in range(predictions.shape[1]):\n",
    "                if result[page][node] == label:\n",
    "                    if empty == False and not isset:\n",
    "                        if DEBUG:\n",
    "                            print(\" \", end='')\n",
    "                        file.write(\" \")\n",
    "                    empty = False\n",
    "                    if label in col_set_dict.keys() and set_total > 0: # That col is a Set\n",
    "                        isset = True\n",
    "                        data.append(node)\n",
    "                        if DEBUG:\n",
    "                            print(\"Append:\" + str(node))\n",
    "                    else:\n",
    "                        if DEBUG:\n",
    "                            print(str(node), end='')\n",
    "                        file.write(str(node))\n",
    "            if label in col_set_dict.keys() and set_total > 0: # That col is a Set\n",
    "                if DEBUG:\n",
    "                    print(str(col_set_dict[label])+\"-\"+str(page), end='')\n",
    "                file.write(str(col_set_dict[label])+\"-\"+str(page))\n",
    "                sets.append(data)\n",
    "            if DEBUG:\n",
    "                print(\"\\t\", end='')\n",
    "            file.write(\"\\t\")\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "        file.write(\"\\n\")\n",
    "        if DEBUG:\n",
    "            print(data)\n",
    "        Set_data.append(sets)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 8s 125ms/sample - loss: 0.5841 - accuracy: 0.9773\n",
      "\n",
      "\n",
      "Loss 0.6916341145833333, Acc 0.9772800207138062\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_acc = model.evaluate([path_train, content_train, feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6], label_train, batch_size=BATCH_SIZE)\n",
    "print(\"\\n\\nLoss {}, Acc {}\".format(model_loss, model_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(col_set_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set data output for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the Set data that being predicted in the Set by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crf/set/Set_data.txt\", \"w\") as set_train_file:\n",
    "        tmp = str(Set_data)\n",
    "        set_train_file.write(tmp)\n",
    "        if DEBUG:\n",
    "            print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set Train File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate train file for Set Model from DCADE Set Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(feature_train_1.shape)\n",
    "\n",
    "feature_train_1 = np.reshape(feature_train_1, [-1, max_num])\n",
    "feature_train_2 = np.reshape(feature_train_2, [-1, max_num])\n",
    "feature_train_3 = np.reshape(feature_train_3, [-1, max_num])\n",
    "feature_train_4 = np.reshape(feature_train_4, [-1, max_num])\n",
    "feature_train_5 = np.reshape(feature_train_5, [-1, max_num])\n",
    "feature_train_6 = np.reshape(feature_train_6, [-1, max_num])\n",
    "label_train = np.reshape(label_train, [-1, max_num, max_label+1])\n",
    "path_train = np.reshape(path_train, [-1, max_num, path_max_len])\n",
    "content_train = np.reshape(content_train, [-1, max_num, con_max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_count = []\n",
    "if set_total > 0:\n",
    "    for set_t in range(set_total):\n",
    "        with open(\"./data/Set-\"+ str(set_t+1) +\".txt\", \"r\") as set_file:\n",
    "            set_tmp = []\n",
    "            output_name = \"./set/Set-\"+ str(set_t+1) +\"_train_raw.csv\"\n",
    "            if DEBUG:\n",
    "                print(\"Generating:\" + output_name + \"\\n\")\n",
    "            output = open(output_name, \"w\")\n",
    "            output.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tPath\\tContent\\tLabel\\n\")\n",
    "            line = set_file.readline()\n",
    "            slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            while(slot[0]!=\"ColType\"): \n",
    "                line = set_file.readline()\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            with open(\"./crf/set/Set-\"+ str(set_t+1) +\"_coltype.txt\", \"w\") as col_file:\n",
    "                col_file.write(str(slot[1:]))\n",
    "            line = set_file.readline() # First line of data\n",
    "            page_num = 0\n",
    "            count = 0\n",
    "            while(line != \"\"):\n",
    "                slot = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                data_info = slot[0].split(\"-\")\n",
    "                if(page_num != int(data_info[1])):\n",
    "                    set_tmp.append(count)\n",
    "                    count = 0\n",
    "                set_num = int(data_info[0])\n",
    "                page_num = int(data_info[1])\n",
    "                if DEBUG:\n",
    "                    print(str(data_info[0])+\"-\"+str(data_info[1])+\"-\"+str(data_info[2]))\n",
    "                idx = 1\n",
    "                sub_list = slot[1:]\n",
    "                while(\"\" in sub_list):\n",
    "                    sub_list.remove(\"\")\n",
    "                while(\" \" in sub_list):\n",
    "                    sub_list.remove(\" \")\n",
    "                for element in sub_list:\n",
    "                    count += 1\n",
    "                    if DEBUG:\n",
    "                        print(element)\n",
    "                    element = int(element)\n",
    "                    output.write(str(feature_train_1[page_num][element])+\"\\t\")\n",
    "                    output.write(str(feature_train_2[page_num][element])+\"\\t\")\n",
    "                    output.write(str(feature_train_3[page_num][element])+\"\\t\")\n",
    "                    output.write(str(feature_train_4[page_num][element])+\"\\t\")\n",
    "                    output.write(str(feature_train_5[page_num][element])+\"\\t\")\n",
    "                    output.write(str(feature_train_6[page_num][element])+\"\\t\")\n",
    "                    output.write(str(list(path_train[page_num][element])))\n",
    "                    output.write(\"\\t\")\n",
    "                    output.write(str(list(content_train[page_num][element])))\n",
    "                    output.write(\"\\t\")\n",
    "                    output.write(str(idx) + \"\\n\")\n",
    "                    if DEBUG:\n",
    "                        print(feature_train_1[page_num][element])\n",
    "                    idx += 1\n",
    "                line = set_file.readline()\n",
    "            set_tmp.append(count)\n",
    "            output.close()\n",
    "        set_data_count.append(set_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crf/set/set_train_count.txt\", \"w\") as file:\n",
    "        file.write(str(set_data_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Set Test file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test file from node data being predicted in a Set by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 1667.67it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 2717.22it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 5485.86it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 2812.08it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 1314.86it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 1486.38it/s]\n"
     ]
    }
   ],
   "source": [
    "set_data_count = []\n",
    "if set_total > 0:\n",
    "    for set_t in range(set_total):\n",
    "        set_tmp = []\n",
    "        with open(\"./crf/set/Set-\"+ str(set_t+1) +\"_ytest_raw.csv\", \"w\") as set_file:\n",
    "            set_file.write(\"Leafnode\\tPTypeSet\\tTypeSet\\tContentid\\tPathid\\tSimseqid\\tPath\\tContent\\tLabel\\n\")\n",
    "            co = 0\n",
    "            for pages in tqdm(range(len(Set_data))):\n",
    "                count = 0\n",
    "                for node in Set_data[pages][set_t]:\n",
    "                    co += 1\n",
    "                    count += 1\n",
    "                    set_file.write(str(feature_train_1[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(feature_train_2[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(feature_train_3[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(feature_train_4[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(feature_train_5[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(feature_train_6[pages][node]))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(list(path_train[pages][node])))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(list(content_train[pages][node])))\n",
    "                    set_file.write(\"\\t\")\n",
    "                    set_file.write(str(0) + \"\\n\")\n",
    "                set_tmp.append(count)\n",
    "            if DEBUG:\n",
    "                print(co)\n",
    "        set_data_count.append(set_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(set_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    with open(\"./crf/set/set_test_count.txt\", \"w\") as file:\n",
    "        file.write(str(set_data_count))\n",
    "    with open(\"./crf/set/word_size.txt\", \"w\") as file:\n",
    "        file.write(str(path_word_size)+\"\\n\")\n",
    "        file.write(str(con_word_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_c = len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_max_len = 30    # padding length\n",
    "path_emb_size = 10    # embedding size\n",
    "\n",
    "con_max_len = 50    # padding length\n",
    "con_emb_size = 10    # embedding size\n",
    "\n",
    "feature_emb_size = 5\n",
    "\n",
    "EPOCHS = 10000        # Train epochs\n",
    "conv_num = 20        # First cnn filter num\n",
    "UNTIL_LOSS = 0.01    # When achieve loss then stop\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001) # Set learning rate\n",
    "NO_IMPROVE = 50     # Stop when no improve for epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_num_set(set_data_count, set_total):\n",
    "    max_set = []\n",
    "    for i in range(set_total):\n",
    "        max_set.append(0)\n",
    "    for sets in range(len(set_data_count)):\n",
    "        max_set[sets] = max(set_data_count[sets])\n",
    "    return max_set\n",
    "\n",
    "def feature_padding_set(df, set_count, set_num):\n",
    "    feature = []\n",
    "    count = 0\n",
    "    for pages in set_count[set_num-1]:\n",
    "        t = []\n",
    "        set_len = pages\n",
    "        for i in range(set_len):\n",
    "            t.append(df[count])\n",
    "            count += 1\n",
    "        if set_len != max_set[set_num-1]:\n",
    "            for i in range(max_set[set_num-1]-set_len):\n",
    "                t.append(9999)\n",
    "        feature.append(t)\n",
    "    return feature\n",
    "\n",
    "def emb_padding_set(df, set_count, set_num, pad_len):\n",
    "    emb = []\n",
    "    tmp = []\n",
    "    for i in range(pad_len):\n",
    "        tmp.append(0)\n",
    "    count = 0\n",
    "    for pages in set_count[set_num-1]:\n",
    "        set_len = pages\n",
    "        for i in range(set_len):\n",
    "            emb.append(eval(df[count]))\n",
    "            count += 1\n",
    "        if set_len != max_set[set_num-1]:\n",
    "            for i in range(max_set[set_num-1]-set_len):\n",
    "                emb.append(tmp)\n",
    "    return emb\n",
    "\n",
    "def one_of_n(ans, total):\n",
    "    tmp = []\n",
    "    for i in range(int(total)):\n",
    "        if ans == i:\n",
    "            tmp.append(1.0)\n",
    "        else:\n",
    "            tmp.append(0.0)\n",
    "    return tmp\n",
    "\n",
    "def label_padding_set(df, set_count, set_num):\n",
    "    label = []\n",
    "    tmp = one_of_n(0, max_label+1)\n",
    "    count = 0\n",
    "    for pages in set_count[set_num-1]:\n",
    "        set_len = pages\n",
    "        for i in range(set_len):\n",
    "            label.append(one_of_n(df[count], max_label+1))\n",
    "            count += 1\n",
    "        if set_len != max_set[set_num-1]:\n",
    "            for i in range(max_set[set_num-1]-set_len):\n",
    "                label.append(tmp)\n",
    "    return label\n",
    "\n",
    "def to_train_array_set(df, set_count, set_num):\n",
    "    feature_1 = np.array(feature_padding_set(df['Leafnode'], set_count, set_num))\n",
    "    feature_2 = np.array(feature_padding_set(df['PTypeSet'], set_count, set_num))\n",
    "    feature_3 = np.array(feature_padding_set(df['TypeSet'], set_count, set_num))\n",
    "    feature_4 = np.array(feature_padding_set(df['Contentid'], set_count, set_num))\n",
    "    feature_5 = np.array(feature_padding_set(df['Pathid'], set_count, set_num))\n",
    "    feature_6 = np.array(feature_padding_set(df['Simseqid'], set_count, set_num))\n",
    "    \n",
    "    path = np.array(emb_padding_set(df['Path'], set_count, set_num, path_max_len))\n",
    "    path = np.reshape(path, [len(set_count[set_num-1]), max_set[set_num-1], path_max_len])\n",
    "    content = np.array(emb_padding_set(df['Content'], set_count, set_num, con_max_len))\n",
    "    content = np.reshape(content, [len(set_count[set_num-1]), max_set[set_num-1], con_max_len])\n",
    "    \n",
    "    label = np.array(label_padding_set(df['Label'], set_count, set_num))\n",
    "    label = np.reshape(label, [len(set_count[set_num-1]), max_set[set_num-1], int(max_label+1)])\n",
    "    return feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, path, content, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_total > 0:\n",
    "    Set_data = []\n",
    "    set_train_count = []\n",
    "    set_test_count = []\n",
    "    with open(\"./crf/set/Set_data.txt\", \"r\") as set_file:\n",
    "        Set_data = eval(set_file.readline())\n",
    "    with open(\"./crf/set/set_train_count.txt\", \"r\") as set_file:\n",
    "        set_train_count = eval(set_file.readline())\n",
    "    with open(\"./crf/set/set_test_count.txt\", \"r\") as set_file:\n",
    "        set_test_count = eval(set_file.readline())\n",
    "    with open(\"./crf/set/word_size.txt\", \"r\") as file:\n",
    "        path_word_size = eval(file.readline())\n",
    "        con_word_size = eval(file.readline())\n",
    "    max_num_train = max_num_set(set_train_count, set_total)\n",
    "    max_num_test = max_num_set(set_test_count, set_total)\n",
    "    max_set = []\n",
    "    for i in range(len(max_num_train)):\n",
    "        max_set.append(max(max_num_train[i], max_num_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop all the set for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "Epoch 1/10000\n",
      "30/30 [==============================] - 3s 85ms/sample - loss: 19.9178 - accuracy: 0.3270\n",
      "Epoch 2/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 18.6429 - accuracy: 0.3047\n",
      "Epoch 3/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 17.8907 - accuracy: 0.3036\n",
      "Epoch 4/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 17.2918 - accuracy: 0.3047\n",
      "Epoch 5/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 16.8848 - accuracy: 0.3047\n",
      "Epoch 6/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 16.5759 - accuracy: 0.3047\n",
      "Epoch 7/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 16.2700 - accuracy: 0.3036\n",
      "Epoch 8/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 15.8605 - accuracy: 0.3036\n",
      "Epoch 9/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 15.4071 - accuracy: 0.3387\n",
      "Epoch 10/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 14.8920 - accuracy: 0.3661\n",
      "Epoch 11/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 14.3316 - accuracy: 0.4258\n",
      "Epoch 12/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 13.7383 - accuracy: 0.6599\n",
      "Epoch 13/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 13.1201 - accuracy: 0.6719\n",
      "Epoch 14/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 12.4454 - accuracy: 0.6719\n",
      "Epoch 15/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 11.7279 - accuracy: 0.6719\n",
      "Epoch 16/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 10.9994 - accuracy: 0.7321\n",
      "Epoch 17/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 10.2736 - accuracy: 0.7344\n",
      "Epoch 18/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 9.5111 - accuracy: 0.7363\n",
      "Epoch 19/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 8.7485 - accuracy: 0.7821\n",
      "Epoch 20/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 7.9923 - accuracy: 0.9238\n",
      "Epoch 21/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 7.2449 - accuracy: 0.9735\n",
      "Epoch 22/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 6.5279 - accuracy: 0.9754\n",
      "Epoch 23/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 5.8448 - accuracy: 0.9754\n",
      "Epoch 24/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 5.2060 - accuracy: 0.9785\n",
      "Epoch 25/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 4.6098 - accuracy: 0.9754\n",
      "Epoch 26/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 4.0649 - accuracy: 0.9785\n",
      "Epoch 27/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 3.5642 - accuracy: 0.9754\n",
      "Epoch 28/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 3.1171 - accuracy: 0.9754\n",
      "Epoch 29/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.7180 - accuracy: 0.9955\n",
      "Epoch 30/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.3690 - accuracy: 0.9955\n",
      "Epoch 31/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.0657 - accuracy: 0.9955\n",
      "Epoch 32/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.8026 - accuracy: 0.9955\n",
      "Epoch 33/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.5771 - accuracy: 0.9955\n",
      "Epoch 34/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.3893 - accuracy: 0.9980\n",
      "Epoch 35/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.2230 - accuracy: 0.9978\n",
      "Epoch 36/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.0860 - accuracy: 0.9980\n",
      "Epoch 37/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.9664 - accuracy: 0.9980\n",
      "Epoch 38/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.8646 - accuracy: 0.9978\n",
      "Epoch 39/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.7780 - accuracy: 0.9978\n",
      "Epoch 40/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.7031 - accuracy: 0.9978\n",
      "Epoch 41/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.6399 - accuracy: 0.9978\n",
      "Epoch 42/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.5858 - accuracy: 0.9978\n",
      "Epoch 43/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.5386 - accuracy: 0.9980\n",
      "Epoch 44/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4968 - accuracy: 0.9978\n",
      "Epoch 45/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4612 - accuracy: 0.9980\n",
      "Epoch 46/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4285 - accuracy: 0.9978\n",
      "Epoch 47/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4013 - accuracy: 0.9980\n",
      "Epoch 48/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3757 - accuracy: 0.9978\n",
      "Epoch 49/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3538 - accuracy: 0.9980\n",
      "Epoch 50/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3335 - accuracy: 1.0000\n",
      "Epoch 51/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3159 - accuracy: 1.0000\n",
      "Epoch 52/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2991 - accuracy: 1.0000\n",
      "Epoch 53/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2848 - accuracy: 1.0000\n",
      "Epoch 54/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2708 - accuracy: 1.0000\n",
      "Epoch 55/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2588 - accuracy: 1.0000\n",
      "Epoch 56/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2474 - accuracy: 1.0000\n",
      "Epoch 57/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2368 - accuracy: 1.0000\n",
      "Epoch 58/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2271 - accuracy: 1.0000\n",
      "Epoch 59/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2181 - accuracy: 1.0000\n",
      "Epoch 60/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2095 - accuracy: 1.0000\n",
      "Epoch 61/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2016 - accuracy: 1.0000\n",
      "Epoch 62/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1950 - accuracy: 1.0000\n",
      "Epoch 63/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 64/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1812 - accuracy: 1.0000\n",
      "Epoch 65/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1753 - accuracy: 1.0000\n",
      "Epoch 66/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1697 - accuracy: 1.0000\n",
      "Epoch 67/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1643 - accuracy: 1.0000\n",
      "Epoch 68/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1585 - accuracy: 1.0000\n",
      "Epoch 69/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 70/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1493 - accuracy: 1.0000\n",
      "Epoch 71/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1449 - accuracy: 1.0000\n",
      "Epoch 72/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1406 - accuracy: 1.0000\n",
      "Epoch 73/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1367 - accuracy: 1.0000\n",
      "Epoch 74/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1328 - accuracy: 1.0000\n",
      "Epoch 75/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1291 - accuracy: 1.0000\n",
      "Epoch 76/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1256 - accuracy: 1.0000\n",
      "Epoch 77/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 78/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 80/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1131 - accuracy: 1.0000\n",
      "Epoch 81/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1101 - accuracy: 1.0000\n",
      "Epoch 82/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 83/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1048 - accuracy: 1.0000\n",
      "Epoch 84/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1023 - accuracy: 1.0000\n",
      "Epoch 85/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0998 - accuracy: 1.0000\n",
      "Epoch 86/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0975 - accuracy: 1.0000\n",
      "Epoch 87/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0953 - accuracy: 1.0000\n",
      "Epoch 88/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0932 - accuracy: 1.0000\n",
      "Epoch 89/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0911 - accuracy: 1.0000\n",
      "Epoch 90/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 91/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0871 - accuracy: 1.0000\n",
      "Epoch 92/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0851 - accuracy: 1.0000\n",
      "Epoch 93/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0833 - accuracy: 1.0000\n",
      "Epoch 94/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0815 - accuracy: 1.0000\n",
      "Epoch 95/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0798 - accuracy: 1.0000\n",
      "Epoch 96/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0782 - accuracy: 1.0000\n",
      "Epoch 97/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 98/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0750 - accuracy: 1.0000\n",
      "Epoch 99/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 100/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 101/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0706 - accuracy: 1.0000\n",
      "Epoch 102/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0692 - accuracy: 1.0000\n",
      "Epoch 103/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0679 - accuracy: 1.0000\n",
      "Epoch 104/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 105/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0653 - accuracy: 1.0000\n",
      "Epoch 106/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 107/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 108/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0616 - accuracy: 1.0000\n",
      "Epoch 109/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 110/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 111/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0584 - accuracy: 1.0000\n",
      "Epoch 112/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 113/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0563 - accuracy: 1.0000\n",
      "Epoch 114/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 115/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 116/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 117/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0525 - accuracy: 1.0000\n",
      "Epoch 118/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 119/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0508 - accuracy: 1.0000\n",
      "Epoch 120/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 121/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 122/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 123/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 124/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 125/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0460 - accuracy: 1.0000\n",
      "Epoch 126/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 127/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 128/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 129/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 130/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 131/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 132/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 133/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 134/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 135/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0394 - accuracy: 1.0000\n",
      "Epoch 136/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 137/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 138/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 139/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 140/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 141/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 142/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 143/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 144/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 145/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 146/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 147/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 148/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 149/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 150/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 151/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 152/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 153/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 154/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 155/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 156/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 158/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 159/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 160/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 161/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 162/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 163/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 164/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 165/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 166/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 167/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 168/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 169/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 170/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 171/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 172/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 173/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 174/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 175/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 176/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 177/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 178/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 179/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 180/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 181/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 182/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 183/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 184/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 185/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 186/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 187/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 188/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 189/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 190/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 191/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 192/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 193/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 194/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 195/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 196/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 197/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 198/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 199/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 200/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 201/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 202/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 203/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 204/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 205/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 206/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 207/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 208/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 209/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 210/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 211/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 212/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 213/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 214/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 215/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 216/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 217/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 218/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 219/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 220/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 221/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 222/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 223/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 224/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 225/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 226/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 227/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 228/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 229/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 230/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 231/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 232/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 233/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 234/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 236/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 237/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 238/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 239/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 240/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 241/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 242/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 243/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 244/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 245/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 246/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 247/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 248/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 249/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 250/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 251/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 252/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 253/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 254/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 255/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 256/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 257/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 258/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 259/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 260/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 261/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 262/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 263/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 264/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 265/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 266/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 267/10000\n",
      "16/30 [===============>..............] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000Epoch 00266: early stopping THR\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 0.0091 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "Loss 0.009886932248870531, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 29592.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "Epoch 1/10000\n",
      "30/30 [==============================] - 3s 96ms/sample - loss: 25.9065 - accuracy: 0.4844\n",
      "Epoch 2/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 21.8752 - accuracy: 0.4731\n",
      "Epoch 3/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 20.5398 - accuracy: 0.4715\n",
      "Epoch 4/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 18.3488 - accuracy: 0.4811\n",
      "Epoch 5/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 15.2958 - accuracy: 0.6443\n",
      "Epoch 6/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 12.4136 - accuracy: 0.7219\n",
      "Epoch 7/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 9.5417 - accuracy: 0.8006\n",
      "Epoch 8/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 7.3021 - accuracy: 0.8636\n",
      "Epoch 9/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 5.7246 - accuracy: 0.8822\n",
      "Epoch 10/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 4.4500 - accuracy: 0.9948\n",
      "Epoch 11/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 3.4104 - accuracy: 1.0000\n",
      "Epoch 12/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.5721 - accuracy: 1.0000\n",
      "Epoch 13/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.9149 - accuracy: 1.0000\n",
      "Epoch 14/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.4275 - accuracy: 1.0000\n",
      "Epoch 15/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.0532 - accuracy: 1.0000\n",
      "Epoch 16/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.7813 - accuracy: 1.0000\n",
      "Epoch 17/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.5816 - accuracy: 1.0000\n",
      "Epoch 18/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4308 - accuracy: 1.0000\n",
      "Epoch 19/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.3275 - accuracy: 1.0000\n",
      "Epoch 20/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2521 - accuracy: 1.0000\n",
      "Epoch 21/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1971 - accuracy: 1.0000\n",
      "Epoch 22/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1558 - accuracy: 1.0000\n",
      "Epoch 23/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1282 - accuracy: 1.0000\n",
      "Epoch 24/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1060 - accuracy: 1.0000\n",
      "Epoch 25/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0897 - accuracy: 1.0000\n",
      "Epoch 26/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0773 - accuracy: 1.0000\n",
      "Epoch 27/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0673 - accuracy: 1.0000\n",
      "Epoch 28/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 29/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0537 - accuracy: 1.0000\n",
      "Epoch 30/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0487 - accuracy: 1.0000\n",
      "Epoch 31/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 32/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 33/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 34/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 35/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 36/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 37/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 38/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 39/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 40/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 41/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 42/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 43/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 44/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 45/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 46/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 47/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 48/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 49/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 50/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 51/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 52/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 53/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 54/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 55/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 56/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 57/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 58/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 59/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 60/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 61/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 62/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 63/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 64/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 65/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 66/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 67/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 68/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 69/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 70/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 71/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 72/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 73/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 74/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 75/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 76/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 77/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 78/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 80/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 81/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 82/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 83/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 84/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 85/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 86/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 87/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 88/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 89/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 90/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 91/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 92/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 93/10000\n",
      "17/30 [================>.............] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000Epoch 00092: early stopping THR\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "Loss 0.009789784935613473, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 30269.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples\n",
      "Epoch 1/10000\n",
      "26/26 [==============================] - 3s 102ms/sample - loss: 15.2623 - accuracy: 0.4769\n",
      "Epoch 2/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 10.4372 - accuracy: 0.7106\n",
      "Epoch 3/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 8.5674 - accuracy: 0.6296\n",
      "Epoch 4/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 6.1457 - accuracy: 0.9120\n",
      "Epoch 5/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 4.9306 - accuracy: 0.9259\n",
      "Epoch 6/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 3.2911 - accuracy: 0.9583\n",
      "Epoch 7/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 2.0760 - accuracy: 0.9792\n",
      "Epoch 8/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 1.5574 - accuracy: 0.9468\n",
      "Epoch 9/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 1.1860 - accuracy: 0.9769\n",
      "Epoch 10/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.9103 - accuracy: 0.9884\n",
      "Epoch 11/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.7737 - accuracy: 0.9907\n",
      "Epoch 12/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.6959 - accuracy: 0.9907\n",
      "Epoch 13/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.5907 - accuracy: 0.9792\n",
      "Epoch 14/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.5167 - accuracy: 0.9792\n",
      "Epoch 15/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.4383 - accuracy: 0.9792\n",
      "Epoch 16/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.3740 - accuracy: 0.9931\n",
      "Epoch 17/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.3603 - accuracy: 0.9931\n",
      "Epoch 18/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.2953 - accuracy: 0.9838\n",
      "Epoch 19/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.2496 - accuracy: 0.9931\n",
      "Epoch 20/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.2158 - accuracy: 0.9954\n",
      "Epoch 21/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.1897 - accuracy: 0.9954\n",
      "Epoch 22/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.1623 - accuracy: 0.9954\n",
      "Epoch 23/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.1416 - accuracy: 0.9977\n",
      "Epoch 24/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 25/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.1076 - accuracy: 1.0000\n",
      "Epoch 26/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 27/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0869 - accuracy: 1.0000\n",
      "Epoch 28/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 29/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 30/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 31/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 32/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 33/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 34/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 35/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 36/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 37/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 38/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 39/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 40/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 41/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 42/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 43/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 44/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 45/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 46/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 47/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 48/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 49/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 50/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 51/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 52/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 53/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 54/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 55/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 56/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 57/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 58/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 59/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 60/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 61/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 62/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 63/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 64/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 65/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 66/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 67/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 68/10000\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 69/10000\n",
      "12/26 [============>.................] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000Epoch 00068: early stopping THR\n",
      "26/26 [==============================] - 0s 3ms/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "26/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 12ms/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "Loss 0.009787339215668349, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 22353.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples\n",
      "Epoch 1/10000\n",
      "27/27 [==============================] - 2s 85ms/sample - loss: 62.2319 - accuracy: 0.0447\n",
      "Epoch 2/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 53.4317 - accuracy: 0.7222\n",
      "Epoch 3/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 42.1661 - accuracy: 0.7222\n",
      "Epoch 4/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 33.4030 - accuracy: 0.7222\n",
      "Epoch 5/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 33.3416 - accuracy: 0.7222\n",
      "Epoch 6/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 35.6195 - accuracy: 0.7222\n",
      "Epoch 7/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 33.9376 - accuracy: 0.7222\n",
      "Epoch 8/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 29.1919 - accuracy: 0.7222\n",
      "Epoch 9/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 24.0465 - accuracy: 0.7222\n",
      "Epoch 10/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 20.9826 - accuracy: 0.7353\n",
      "Epoch 11/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 20.0950 - accuracy: 0.8377\n",
      "Epoch 12/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 19.8281 - accuracy: 0.8769\n",
      "Epoch 13/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 19.1957 - accuracy: 0.9041\n",
      "Epoch 14/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 18.0488 - accuracy: 0.9085\n",
      "Epoch 15/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 16.6594 - accuracy: 0.8998\n",
      "Epoch 16/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 15.3154 - accuracy: 0.8889\n",
      "Epoch 17/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 14.1426 - accuracy: 0.9009\n",
      "Epoch 18/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 13.1398 - accuracy: 0.9401\n",
      "Epoch 19/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 12.2727 - accuracy: 0.9532\n",
      "Epoch 20/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 11.5169 - accuracy: 0.9553\n",
      "Epoch 21/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 10.8503 - accuracy: 0.9564\n",
      "Epoch 22/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 10.2362 - accuracy: 0.9619\n",
      "Epoch 23/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 9.6272 - accuracy: 0.9673\n",
      "Epoch 24/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 8.9921 - accuracy: 0.9695\n",
      "Epoch 25/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 8.3393 - accuracy: 0.9728\n",
      "Epoch 26/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 7.7058 - accuracy: 0.9728\n",
      "Epoch 27/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 7.1188 - accuracy: 0.9749\n",
      "Epoch 28/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 6.5721 - accuracy: 0.9804\n",
      "Epoch 29/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 6.0404 - accuracy: 0.9815\n",
      "Epoch 30/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 5.5121 - accuracy: 0.9815\n",
      "Epoch 31/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 4.9985 - accuracy: 0.9837\n",
      "Epoch 32/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 4.5201 - accuracy: 0.9847\n",
      "Epoch 33/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 4.0879 - accuracy: 0.9858\n",
      "Epoch 34/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 3.7008 - accuracy: 0.9869\n",
      "Epoch 35/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 3.3514 - accuracy: 0.9880\n",
      "Epoch 36/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 3.0353 - accuracy: 0.9880\n",
      "Epoch 37/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 2.7503 - accuracy: 0.9880\n",
      "Epoch 38/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 2.4963 - accuracy: 0.9880\n",
      "Epoch 39/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 2.2718 - accuracy: 0.9880\n",
      "Epoch 40/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 2.0736 - accuracy: 0.9880\n",
      "Epoch 41/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.8990 - accuracy: 0.9880\n",
      "Epoch 42/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.7447 - accuracy: 0.9869\n",
      "Epoch 43/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.6078 - accuracy: 0.9880\n",
      "Epoch 44/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 1.4861 - accuracy: 0.9891\n",
      "Epoch 45/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.3772 - accuracy: 0.9913\n",
      "Epoch 46/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.2803 - accuracy: 0.9913\n",
      "Epoch 47/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.1928 - accuracy: 0.9924\n",
      "Epoch 48/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.1142 - accuracy: 0.9924\n",
      "Epoch 49/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 1.0429 - accuracy: 0.9924\n",
      "Epoch 50/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.9783 - accuracy: 0.9935\n",
      "Epoch 51/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.9196 - accuracy: 0.9946\n",
      "Epoch 52/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.8653 - accuracy: 0.9946\n",
      "Epoch 53/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.8156 - accuracy: 0.9946\n",
      "Epoch 54/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.7699 - accuracy: 0.9967\n",
      "Epoch 55/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.7274 - accuracy: 0.9989\n",
      "Epoch 56/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.6878 - accuracy: 0.9989\n",
      "Epoch 57/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.6512 - accuracy: 1.0000\n",
      "Epoch 58/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.6171 - accuracy: 1.0000\n",
      "Epoch 59/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.5853 - accuracy: 1.0000\n",
      "Epoch 60/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.5556 - accuracy: 1.0000\n",
      "Epoch 61/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.5281 - accuracy: 1.0000\n",
      "Epoch 62/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.5025 - accuracy: 1.0000\n",
      "Epoch 63/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.4786 - accuracy: 1.0000\n",
      "Epoch 64/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.4559 - accuracy: 1.0000\n",
      "Epoch 65/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.4346 - accuracy: 1.0000\n",
      "Epoch 66/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.4149 - accuracy: 1.0000\n",
      "Epoch 67/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3961 - accuracy: 1.0000\n",
      "Epoch 68/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3785 - accuracy: 1.0000\n",
      "Epoch 69/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3618 - accuracy: 1.0000\n",
      "Epoch 70/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3461 - accuracy: 1.0000\n",
      "Epoch 71/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3313 - accuracy: 1.0000\n",
      "Epoch 72/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3174 - accuracy: 1.0000\n",
      "Epoch 73/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.3040 - accuracy: 1.0000\n",
      "Epoch 74/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2915 - accuracy: 1.0000\n",
      "Epoch 75/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2798 - accuracy: 1.0000\n",
      "Epoch 76/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2687 - accuracy: 1.0000\n",
      "Epoch 77/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2578 - accuracy: 1.0000\n",
      "Epoch 78/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.2480 - accuracy: 1.0000\n",
      "Epoch 79/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2387 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2295 - accuracy: 1.0000\n",
      "Epoch 81/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2210 - accuracy: 1.0000\n",
      "Epoch 82/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2126 - accuracy: 1.0000\n",
      "Epoch 83/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.2051 - accuracy: 1.0000\n",
      "Epoch 84/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1978 - accuracy: 1.0000\n",
      "Epoch 85/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1909 - accuracy: 1.0000\n",
      "Epoch 86/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 87/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1778 - accuracy: 1.0000\n",
      "Epoch 88/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1719 - accuracy: 1.0000\n",
      "Epoch 89/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 90/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1605 - accuracy: 1.0000\n",
      "Epoch 91/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1554 - accuracy: 1.0000\n",
      "Epoch 92/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1507 - accuracy: 1.0000\n",
      "Epoch 93/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1460 - accuracy: 1.0000\n",
      "Epoch 94/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1418 - accuracy: 1.0000\n",
      "Epoch 95/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1375 - accuracy: 1.0000\n",
      "Epoch 96/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1333 - accuracy: 1.0000\n",
      "Epoch 97/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1295 - accuracy: 1.0000\n",
      "Epoch 98/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1259 - accuracy: 1.0000\n",
      "Epoch 99/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 100/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.1192 - accuracy: 1.0000\n",
      "Epoch 101/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1157 - accuracy: 1.0000\n",
      "Epoch 102/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 103/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1097 - accuracy: 1.0000\n",
      "Epoch 104/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 105/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1042 - accuracy: 1.0000\n",
      "Epoch 106/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.1019 - accuracy: 1.0000\n",
      "Epoch 107/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 108/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0970 - accuracy: 1.0000\n",
      "Epoch 109/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0945 - accuracy: 1.0000\n",
      "Epoch 110/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0923 - accuracy: 1.0000\n",
      "Epoch 111/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0903 - accuracy: 1.0000\n",
      "Epoch 112/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0884 - accuracy: 1.0000\n",
      "Epoch 113/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 114/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0844 - accuracy: 1.0000\n",
      "Epoch 115/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 116/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0812 - accuracy: 1.0000\n",
      "Epoch 117/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0794 - accuracy: 1.0000\n",
      "Epoch 118/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 119/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 120/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 121/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 122/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 123/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0707 - accuracy: 1.0000\n",
      "Epoch 124/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 125/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 126/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 127/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0658 - accuracy: 1.0000\n",
      "Epoch 128/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 129/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 130/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 131/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0614 - accuracy: 1.0000\n",
      "Epoch 132/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 133/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 134/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 135/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 136/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 137/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0561 - accuracy: 1.0000\n",
      "Epoch 138/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 139/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0543 - accuracy: 1.0000\n",
      "Epoch 140/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0537 - accuracy: 1.0000\n",
      "Epoch 141/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 142/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0520 - accuracy: 1.0000\n",
      "Epoch 143/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 144/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 145/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 146/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 147/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 148/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 149/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0472 - accuracy: 1.0000\n",
      "Epoch 150/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0469 - accuracy: 1.0000\n",
      "Epoch 151/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0462 - accuracy: 1.0000\n",
      "Epoch 152/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 153/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 154/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 155/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 156/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0434 - accuracy: 1.0000\n",
      "Epoch 157/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 158/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0423 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 160/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 161/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 162/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0403 - accuracy: 1.0000\n",
      "Epoch 163/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 164/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0394 - accuracy: 1.0000\n",
      "Epoch 165/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 166/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 167/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 168/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 169/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 170/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 171/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 172/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 173/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 174/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 175/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 176/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 177/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 178/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 179/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 180/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 181/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 182/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 183/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 184/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 185/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 186/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 187/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 188/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 189/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 190/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 191/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 192/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 193/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 194/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 195/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 196/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 197/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 198/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 199/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 200/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 201/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 202/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 203/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 204/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 205/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 206/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 207/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 208/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 209/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 210/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 211/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 212/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 213/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 214/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 215/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 216/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 217/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 218/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 219/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 220/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 221/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 222/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 223/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 224/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 225/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 226/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 227/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 228/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 229/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 230/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 231/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 232/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 233/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 234/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 235/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 236/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 238/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 239/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 240/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 241/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 242/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 243/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 244/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 245/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 246/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 247/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 248/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 249/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 250/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 251/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 252/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 253/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 254/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 255/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 256/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 257/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 258/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 259/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 260/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 261/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 262/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 263/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 264/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 265/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 266/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 267/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 268/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 269/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 270/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 271/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 272/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 273/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 274/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 275/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 276/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 277/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 278/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 279/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 280/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 281/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 282/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 283/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 284/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 285/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 286/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 287/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 288/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 289/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 290/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 291/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 292/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 293/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 294/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 295/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 296/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 297/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 298/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 299/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 300/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 301/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 302/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 303/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 304/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 305/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 306/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 307/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 308/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 309/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 310/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 311/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 312/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 313/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 314/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 315/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0138 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 317/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 318/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 319/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 320/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 321/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 322/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 323/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 324/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 325/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 326/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 327/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 328/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 329/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 330/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 331/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 332/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 333/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 334/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 335/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 336/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 337/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 338/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 339/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 340/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 341/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 342/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 343/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 344/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 345/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 346/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 347/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 348/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 349/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 350/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 351/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 352/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 353/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 354/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 355/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 356/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 357/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 358/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 359/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 360/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 361/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 362/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 363/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 364/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 365/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 366/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 367/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 368/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 369/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 370/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 371/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 372/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 373/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 374/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 375/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 376/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 377/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 378/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 379/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 380/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 381/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 382/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 383/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 384/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 385/10000\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 386/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 387/10000\n",
      "27/27 [==============================] - 0s 1ms/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 388/10000\n",
      "Epoch 00387: early stopping THR\n",
      "27/27 [==============================] - 0s 2ms/sample - loss: 0.0100 - accuracy: 1.0000\n",
      "27/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 0.0102 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss 0.0102403424680233, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 9423.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "Epoch 1/10000\n",
      "30/30 [==============================] - 2s 81ms/sample - loss: 43.3708 - accuracy: 0.1512\n",
      "Epoch 2/10000\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 37.7158 - accuracy: 0.2720\n",
      "Epoch 3/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 33.7252 - accuracy: 0.2976\n",
      "Epoch 4/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 28.6463 - accuracy: 0.8000\n",
      "Epoch 5/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 22.7555 - accuracy: 0.7504\n",
      "Epoch 6/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 15.9639 - accuracy: 0.7528\n",
      "Epoch 7/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 10.0222 - accuracy: 0.9000\n",
      "Epoch 8/10000\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 5.5548 - accuracy: 1.0000\n",
      "Epoch 9/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 2.9352 - accuracy: 1.0000\n",
      "Epoch 10/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.4831 - accuracy: 1.0000\n",
      "Epoch 11/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.8407 - accuracy: 1.0000\n",
      "Epoch 12/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4359 - accuracy: 1.0000\n",
      "Epoch 13/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2416 - accuracy: 1.0000\n",
      "Epoch 14/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1512 - accuracy: 1.0000\n",
      "Epoch 15/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1031 - accuracy: 1.0000\n",
      "Epoch 16/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 17/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 18/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 19/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 20/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 21/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 22/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 23/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 24/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 25/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 26/10000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000Epoch 00025: early stopping THR\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 0.0090 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "Loss 0.008845011393229166, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 16661.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "Epoch 1/10000\n",
      "30/30 [==============================] - 2s 74ms/sample - loss: 36.8452 - accuracy: 0.5382\n",
      "Epoch 2/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 29.3756 - accuracy: 0.4757\n",
      "Epoch 3/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 23.7436 - accuracy: 0.4983\n",
      "Epoch 4/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 20.7556 - accuracy: 0.5174\n",
      "Epoch 5/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 16.8235 - accuracy: 0.9488\n",
      "Epoch 6/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 12.2166 - accuracy: 0.9514\n",
      "Epoch 7/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 7.8275 - accuracy: 0.9722\n",
      "Epoch 8/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 4.5792 - accuracy: 0.9826\n",
      "Epoch 9/10000\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 2.6915 - accuracy: 0.9826\n",
      "Epoch 10/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.6919 - accuracy: 0.9826\n",
      "Epoch 11/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 1.0844 - accuracy: 0.9722\n",
      "Epoch 12/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.6928 - accuracy: 0.9991\n",
      "Epoch 13/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.4542 - accuracy: 1.0000\n",
      "Epoch 14/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.2434 - accuracy: 1.0000\n",
      "Epoch 15/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 16/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.1237 - accuracy: 1.0000\n",
      "Epoch 17/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0948 - accuracy: 1.0000\n",
      "Epoch 18/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 19/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 20/10000\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 21/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 22/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 23/10000\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 24/10000\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 25/10000\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000Epoch 00024: early stopping THR\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 0.0097 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "Loss 0.008127339463680983, Acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 31671.06it/s]\n"
     ]
    }
   ],
   "source": [
    "if set_total > 0:\n",
    "    for num in range(set_total):\n",
    "        set_num = num + 1\n",
    "        df = get_df(\"./set/Set-\"+str(set_num)+\"_train_raw.csv\")\n",
    "        max_num = max_set[set_num-1]\n",
    "        max_label = max(df['Label'])\n",
    "        feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6, path_train, content_train, label_train = to_train_array_set(df, set_train_count, set_num)\n",
    "        crf = CRF(False)\n",
    "        BATCH_SIZE = max_num      # Training bath size\n",
    "        VAL_BATCH_SIZE = max_num  # Validation batch size\n",
    "        \n",
    "        def get_model():\n",
    "            path_input = tf.keras.Input(shape=(max_num, path_max_len), name='Path_emb_input')\n",
    "            content_input = tf.keras.Input(shape=(max_num, con_max_len), name='Content_emb_input')\n",
    "            feature_input_1 = tf.keras.Input(shape=(max_num,), name='Feature_input1')\n",
    "            feature_input_2 = tf.keras.Input(shape=(max_num,), name='Feature_input2')\n",
    "            feature_input_3 = tf.keras.Input(shape=(max_num,), name='Feature_input3')\n",
    "            feature_input_4 = tf.keras.Input(shape=(max_num,), name='Feature_input4')\n",
    "            feature_input_5 = tf.keras.Input(shape=(max_num,), name='Feature_input5')\n",
    "            feature_input_6 = tf.keras.Input(shape=(max_num,), name='Feature_input6')\n",
    "\n",
    "            path_f = tf.keras.layers.Flatten()(path_input)\n",
    "            content_f = tf.keras.layers.Flatten()(content_input)\n",
    "\n",
    "            path_emb = tf.keras.layers.Embedding(path_word_size+1, path_emb_size)(path_f)\n",
    "            content_emb = tf.keras.layers.Embedding(con_word_size+1, con_emb_size)(content_f)\n",
    "            f_1_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_1)\n",
    "            f_2_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_2)\n",
    "            f_3_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_3)\n",
    "            f_4_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_4)\n",
    "            f_5_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_5)\n",
    "            f_6_emb = tf.keras.layers.Embedding(100000, feature_emb_size)(feature_input_6)\n",
    "\n",
    "            path_emb = tf.reshape(path_emb, [-1, max_num, path_max_len*path_emb_size])\n",
    "            content_emb = tf.reshape(content_emb, [-1, max_num, con_max_len*con_emb_size])\n",
    "\n",
    "            path_emb = tf.expand_dims(path_emb, -1)\n",
    "            content_emb = tf.expand_dims(content_emb, -1)\n",
    "\n",
    "            path_feature = tf.keras.layers.Conv2D(conv_num, kernel_size=(3,  path_max_len*path_emb_size), strides=(1, path_max_len*path_emb_size), name='Conv_for_Path_emb', padding='same')(path_emb)\n",
    "            content_feature = tf.keras.layers.Conv2D(conv_num, kernel_size=(3, con_max_len*con_emb_size), strides=(1, con_max_len*con_emb_size), name='Conv_for_Content_emb', padding='same')(content_emb)\n",
    "\n",
    "            path = tf.reshape(path_feature, [-1, conv_num])\n",
    "            content = tf.reshape(content_feature, [-1, conv_num])\n",
    "\n",
    "            f_1_emb = tf.reshape(f_1_emb, [-1, feature_emb_size])\n",
    "            f_2_emb = tf.reshape(f_2_emb, [-1, feature_emb_size])\n",
    "            f_3_emb = tf.reshape(f_3_emb, [-1, feature_emb_size])\n",
    "            f_4_emb = tf.reshape(f_4_emb, [-1, feature_emb_size])\n",
    "            f_5_emb = tf.reshape(f_5_emb, [-1, feature_emb_size])\n",
    "            f_6_emb = tf.reshape(f_6_emb, [-1, feature_emb_size])\n",
    "\n",
    "            combine = tf.keras.layers.concatenate([path, content, f_1_emb, f_2_emb, f_3_emb, f_4_emb, f_5_emb, f_6_emb], -1)\n",
    "            d = combine\n",
    "            d = tf.keras.layers.Dense(max_label+1)(d)\n",
    "            d = tf.reshape(d, [-1, max_num, max_label+1])\n",
    "            output = crf(d)\n",
    "            model = tf.keras.Model(inputs=[path_input, content_input, feature_input_1, feature_input_2, feature_input_3, feature_input_4, feature_input_5, feature_input_6], outputs=output)\n",
    "\n",
    "            return model\n",
    "        \n",
    "        model = get_model()\n",
    "        model.compile(\n",
    "            loss=crf.loss,\n",
    "            optimizer=opt,\n",
    "            metrics=[crf.accuracy]\n",
    "        )\n",
    "        history = LossHistory()\n",
    "        stop_when_no_improve = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=0, patience = NO_IMPROVE, restore_best_weights=True)\n",
    "        until_loss = EarlyStoppingByLossVal(monitor='loss', value=UNTIL_LOSS, verbose=1)\n",
    "        callbacks = [history, stop_when_no_improve, until_loss]\n",
    "        \n",
    "        start = time.time()\n",
    "        model.fit([path_train, content_train, feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6], label_train, epochs=EPOCHS, callbacks=callbacks, use_multiprocessing=True, batch_size=BATCH_SIZE)\n",
    "        t += time.time()-start\n",
    "        \n",
    "        model_loss, model_acc = model.evaluate([path_train, content_train, feature_train_1, feature_train_2, feature_train_3, feature_train_4, feature_train_5, feature_train_6], label_train, batch_size=BATCH_SIZE)\n",
    "        print(\"\\n\\nLoss {}, Acc {}\".format(model_loss, model_acc))\n",
    "        model.save_weights(\"./crf/set/set-\"+str(set_num)+\"_cnn-crf.h5\")\n",
    "        del model\n",
    "        \n",
    "        model = get_model()\n",
    "        model.compile(\n",
    "            loss=crf.loss,\n",
    "            optimizer=opt,\n",
    "            metrics=[crf.accuracy]\n",
    "        )\n",
    "        model.load_weights(\"./crf/set/set-\"+str(set_num)+\"_cnn-crf.h5\")\n",
    "        \n",
    "        df = get_df(\"./crf/set/Set-\"+str(set_num)+\"_ytest_raw.csv\")\n",
    "        feature_test_1, feature_test_2, feature_test_3, feature_test_4, feature_test_5, feature_test_6, path_test, content_test, label_test = to_train_array_set(df, set_test_count, set_num)\n",
    "        \n",
    "        with open(\"./crf/set/word_size.txt\", \"r\") as file:\n",
    "            path_word_size = eval(file.readline())\n",
    "            con_word_size = eval(file.readline())\n",
    "        ts_start = time.time()\n",
    "        predictions = model.predict([path_test, content_test, feature_test_1, feature_test_2, feature_test_3, feature_test_4, feature_test_5, feature_test_6], batch_size=VAL_BATCH_SIZE)\n",
    "        ts += time.time()-ts_start\n",
    "        \n",
    "        result = []\n",
    "        for page in range(predictions.shape[0]):\n",
    "            tmp = []\n",
    "            for node in range(max_num):\n",
    "                tmp.append(np.argmax(predictions[page][node]))\n",
    "            result.append(tmp)\n",
    "            \n",
    "        col_type = []\n",
    "        with open(\"./crf/set/Set-\"+str(set_num)+\"_coltype.txt\", \"r\") as file:\n",
    "            tmp = file.readline()\n",
    "            slot = eval(tmp)\n",
    "            col_type = slot\n",
    "        Set = []\n",
    "        with open(\"./crf/set/set-\"+str(set_num)+\".csv\", \"w\") as file: # Create prediction file\n",
    "            for col in col_type: # loop to write the Col type\n",
    "                file.write(col + \"\\t\")\n",
    "                if DEBUG:\n",
    "                    print(col + \"\\t\", end='')\n",
    "            if DEBUG:\n",
    "                print(\"\")\n",
    "            file.write(\"\\n\")\n",
    "            current_pos = 1\n",
    "            for page in tqdm(range(len(result))): # Loop each page\n",
    "                p_tmp = []\n",
    "                for cols in range(max_label+1):\n",
    "                    c_tmp = []\n",
    "                    for node in range(len(result[page])):\n",
    "                        r = result[page][node]\n",
    "                        if r == cols:\n",
    "                            c_tmp.append(node)\n",
    "                    p_tmp.append(c_tmp)\n",
    "                Set.append(p_tmp)\n",
    "            Set_tmp = Set.copy()\n",
    "            for page in range(len(Set_tmp)):\n",
    "                empty = False\n",
    "                col = []\n",
    "                for i in range(len(Set_tmp[page])):\n",
    "                    col.append(False)\n",
    "                col[0] = True\n",
    "                while(not empty):\n",
    "                    for cols in range(len(Set_tmp[page])):\n",
    "                        if len(Set_tmp[page][cols]) == 0:\n",
    "                            col[cols] = True\n",
    "                            if cols != 0:\n",
    "                                if DEBUG:\n",
    "                                    print(\"\\t\", end=\"\")\n",
    "                                file.write(\"\\t\")\n",
    "                        else:\n",
    "                            n = str(int(feature_test_1[page][Set_tmp[page][cols][0]]))\n",
    "                            if cols != 0:\n",
    "                                if DEBUG:\n",
    "                                    print(n+\"\\t\", end=\"\")\n",
    "                                file.write(n+\"\\t\")\n",
    "                            del Set_tmp[page][cols][0]\n",
    "                            if len(Set_tmp[page][cols]) == 0:\n",
    "                                col[cols] = True\n",
    "                        empty = True\n",
    "                        for i in col:\n",
    "                            if i == False:\n",
    "                                empty = False\n",
    "                                break\n",
    "                    if DEBUG:\n",
    "                        print(\"\\n\", end=\"\")\n",
    "                    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train time:1100.1021165847778\n",
      "test time:1.3785645961761475\n",
      "per page:0.04595215320587158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timef = open(\"./crf/data/time_crf.txt\",\"w\")\n",
    "print(\"\\ntrain time:\"+str(t))\n",
    "timef.write(\"train:\"+str(t)+\"\\n\")\n",
    "print(\"test time:\"+str(ts))\n",
    "print(\"per page:\"+ str(float(ts)/page_c)+\"\\n\")\n",
    "timef.write(\"test:\"+str(ts)+\"\\n\")\n",
    "timef.write(\"per page:\"+ str(float(ts)/page_c)+\"\\n\")\n",
    "timef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
