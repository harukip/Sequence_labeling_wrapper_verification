{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import prepare_train_with_set as prepare\n",
    "import os\n",
    "import func\n",
    "import set_func\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRFSuite_process_data(df, max_num, max_label):\n",
    "    '''\n",
    "    Load the csv file and convert it to numpy array for train and test.\n",
    "    '''\n",
    "    num, index = func.node_num(df['Leafnode'])\n",
    "    print(num)\n",
    "    cols = ['Leafnode', 'PTypeSet', 'TypeSet', 'Contentid', 'Pathid', 'Simseqid']\n",
    "    features = []\n",
    "    for c in range(len(cols)):\n",
    "        features.append(np.array(func.node_data(df[cols[c]], num, max_num)))\n",
    "        features[c] = np.expand_dims(features[c], -1)\n",
    "    \n",
    "    feature = np.concatenate([feature for feature in features], -1)\n",
    "    feature = np.reshape(feature, [features[0].shape[0]*max_num, 6])\n",
    "    \n",
    "    label_array = np.array(func.label_padding(df['Label'], num, max_num)).astype('int32')\n",
    "    m_label = df['Label'].max()\n",
    "    label_array = label_array.flatten()\n",
    "    return feature, label_array, m_label\n",
    "\n",
    "def CRFSuite_process_set(df, set_count, set_num, max_set):\n",
    "    cols = ['Leafnode', 'PTypeSet', 'TypeSet', 'Contentid', 'Pathid', 'Simseqid']\n",
    "    features = []\n",
    "    for c in range(len(cols)):\n",
    "        features.append(np.array(set_func.feature_padding_set(df[cols[c]], set_count, set_num, max_set)))\n",
    "        features[c] = np.expand_dims(features[c], -1)\n",
    "    \n",
    "    features = np.concatenate([feature for feature in features], -1)\n",
    "    features = np.reshape(features, [len(set_count[set_num]) * max_set[set_num], 6])\n",
    "    \n",
    "    label = np.array(set_func.label_padding_set(df['Label'], set_count, set_num, max_set))\n",
    "    label = np.reshape(label, [len(set_count[set_num]) * max_set[set_num]])\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    return sklearn_crfsuite.CRF(\n",
    "        c1=0.1,\n",
    "        max_iterations=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # How many Set\n",
    "    model_name = \"crfsuite\"\n",
    "    current_path = os.path.join(os.path.expanduser(\"~\"), \"jupyter\", \n",
    "                                \"Sequence_Labeling_Wrapper_Verification\", \"data\")\n",
    "    websites_set = []\n",
    "    websites_num_train = []\n",
    "    websites_num_test = []\n",
    "    websites_label_train = []\n",
    "    websites_train_data = []\n",
    "    websites_test_data = []\n",
    "    websites_Set_dict = []\n",
    "    websites_col_set_dict = []\n",
    "    all_train_data = pd.DataFrame()\n",
    "    \n",
    "    websites = sorted(glob.glob(current_path+\"/*\"))\n",
    "    for website in websites:\n",
    "        data_path = os.path.join(website, \"data\")\n",
    "        set_total = len(glob.glob(os.path.join(data_path, \"Set-*\")))\n",
    "        websites_set.append(set_total)\n",
    "        # Process training file\n",
    "        train_data, Set_dict = prepare.train_file_generate(set_total, website)\n",
    "        col_set_dict = dict(map(reversed, Set_dict.items()))\n",
    "        test_data = prepare.test_file_generate(website)\n",
    "        num_train, label_train = func.load_data_num(train_data, True)\n",
    "        num_test = func.load_data_num(test_data, False)\n",
    "        all_train_data = pd.concat([all_train_data, train_data], axis=0)\n",
    "        websites_train_data.append(train_data)\n",
    "        websites_test_data.append(test_data)\n",
    "        websites_num_train.append(num_train)\n",
    "        websites_num_test.append(num_test)\n",
    "        websites_label_train.append(label_train)\n",
    "        websites_Set_dict.append(Set_dict)\n",
    "        websites_col_set_dict.append(col_set_dict)\n",
    "        \n",
    "    max_num = max(max(websites_num_train), max(websites_num_test))\n",
    "    max_label_train = max(websites_label_train)\n",
    "    print(\"Max num:\", max_num)\n",
    "    print(\"Max set:\", max(websites_set))\n",
    "    \n",
    "    all_train_data = all_train_data.reset_index().drop('index', axis=1)\n",
    "    feature_train, label_train, _ = CRFSuite_process_data(all_train_data, \n",
    "                                                          max_num, max_label_train)\n",
    "    feature_train = feature_train.tolist()\n",
    "    label_train = label_train.tolist()\n",
    "    X_train = [func.sent2features(feature_train)]\n",
    "    y_train = [func.sent2labels(label_train)]\n",
    "    \n",
    "    # Define model\n",
    "    crf = model()\n",
    "    \n",
    "    # Start training\n",
    "    start = time.time()\n",
    "    crf.fit(X_train, y_train)\n",
    "    t = time.time() - start\n",
    "    \n",
    "    websites_set_train_count = []\n",
    "    websites_set_test_count = []\n",
    "    \n",
    "    for website in range(len(websites)):\n",
    "        feature_train, label_train, _ = CRFSuite_process_data(websites_train_data[website], \n",
    "                                                              max_num, max_label_train)\n",
    "        feature_train = feature_train.tolist()\n",
    "        # Process testing file\n",
    "        feature_test, label_test, _ = CRFSuite_process_data(websites_test_data[website], \n",
    "                                                            max_num, max_label_train)\n",
    "        feature_test = feature_test.tolist()\n",
    "        label_test = label_test.tolist()\n",
    "        X_test = [func.sent2features(feature_test)]\n",
    "        page_test = int(len(feature_test)/max_num)\n",
    "    \n",
    "        # Start testing\n",
    "        ts_start = time.time()\n",
    "        y_pred = crf.predict(X_test)\n",
    "        ts = time.time() - ts_start\n",
    "    \n",
    "        # Process output\n",
    "        y_pred = np.array(y_pred)\n",
    "        result = np.reshape(y_pred, [page_test, max_num])\n",
    "        result = result.astype(np.int32)\n",
    "    \n",
    "        col_type = func.get_col_type(websites[website])\n",
    "        Set_data = func.predict_output(set_total, websites[website], model_name, \n",
    "                                       col_type, result, max_label_train, \n",
    "                                       websites_col_set_dict[website])\n",
    "        set_train_data, set_train_count = set_func.Set_train_file_generate(set_total, \n",
    "                                                                           websites[website], \n",
    "                                                                           model_name, \n",
    "                                                                           feature_train, \n",
    "                                                                           \"\", max_num)\n",
    "        set_test_data, set_test_count = set_func.Set_test_file_generate(set_total, websites[website], \n",
    "                                                                        model_name, Set_data, \n",
    "                                                                        feature_test, \"\", max_num)\n",
    "        page_c = len(result)\n",
    "    \n",
    "    \"\"\"# Process set\n",
    "    for website in range(len(websites)):\n",
    "        set_total = websites_set[website]\n",
    "    \n",
    "        if set_total > 0:\n",
    "        max_num_train = set_func.max_num_set(set_total, set_train_count)\n",
    "        max_num_test = set_func.max_num_set(set_total, set_test_count)\n",
    "        max_set = []\n",
    "        for i in range(len(max_num_train)):\n",
    "            max_set.append(max(max_num_train[i], max_num_test[i]))\n",
    "\n",
    "        for num in range(set_total):\n",
    "            set_feature_train, set_label_train = CRFSuite_process_set(set_train_data[num], set_train_count, num, max_set)\n",
    "            max_num = max_set[num]\n",
    "            max_label = max(set_train_data[num]['Label'])\n",
    "            page_num = int(len(set_feature_train)/max_num)\n",
    "            crf = model()\n",
    "            set_feature_train = set_feature_train.tolist()\n",
    "            set_label_train = set_label_train.tolist()\n",
    "            X_train = [func.sent2features(set_feature_train)]\n",
    "            y_train = [func.sent2labels(set_label_train)]\n",
    "\n",
    "            # Train\n",
    "            start = time.time()\n",
    "            crf.fit(X_train, y_train)\n",
    "            t += time.time()-start\n",
    "\n",
    "            # Load Test file\n",
    "            set_feature_test, set_label_test = CRFSuite_process_set(set_test_data[num], set_test_count, num, max_set)\n",
    "            set_feature_test = set_feature_test.tolist()\n",
    "            set_label_test = set_label_test.tolist()\n",
    "            X_test = [func.sent2features(set_feature_test)]\n",
    "            page_test = int(len(set_feature_test) / max_num)\n",
    "\n",
    "            # Prediction\n",
    "            ts_start = time.time()\n",
    "            y_pred = crf.predict(X_test)\n",
    "            ts += time.time() - ts_start\n",
    "\n",
    "            y_pred = np.array(y_pred)\n",
    "            result = np.reshape(y_pred, [page_test, max_num])\n",
    "            result = result.astype(np.int64)\n",
    "            # Read Col\n",
    "            col_type = set_func.get_col_type(current_path, num)\n",
    "\n",
    "            # Output\n",
    "            set_func.predict_output(current_path, model_name, num, col_type, result, max_label, set_feature_test, max_num)\n",
    "            \n",
    "    # Process time\n",
    "    func.process_time(current_path, model_name, t, ts, page_c)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
